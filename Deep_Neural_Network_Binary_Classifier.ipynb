{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Neural Network Binary Classifier",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KieranJP/Neural-Network-Binary-Classifier/blob/master/Deep_Neural_Network_Binary_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "taMS2EsFt6hm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**This allows me to upload the csv files used as the training and the test data fom my PC:**"
      ]
    },
    {
      "metadata": {
        "id": "s55CvUy25TWe",
        "colab_type": "code",
        "outputId": "58d33839-4f64-4862-ba45-ba1668fa68aa",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "#Uploading Test Data\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-de292b4b-3962-46aa-a226-6f4e89ade434\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-de292b4b-3962-46aa-a226-6f4e89ade434\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving FullELFFDataset.csv to FullELFFDataset.csv\n",
            "User uploaded file \"FullELFFDataset.csv\" with length 14744861 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i8BZisTk6HPl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras as K\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot\n",
        "\n",
        "#Imports Required\n",
        "import numpy\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#Selecting the Csv to use then Displaying it\n",
        "import pandas as pd\n",
        "dataset = pd.read_csv(\"FullELFFDataset.csv\")\n",
        "dataset.columns\n",
        "\n",
        "#Using sklearn's split function to split the data into training and testing data.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = dataset.values\n",
        "Y = dataset.Defective.values\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D8FEI3TuRC0e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "#Attempt at creating a Grid Search to optimise hyperparamter\n",
        "\n",
        "def create_model(batch=64, epoch=250, optimizer='adam', learn_rate=0.0001, activation='relu'):\n",
        "  model = Sequential()\n",
        "  model.add(K.layers.Dense(units=40, input_dim=40, activation='relu', kernel_initializer='truncated_normal')) \n",
        "  model.add(K.layers.Dense(units=32, activation='relu', kernel_initializer='truncated_normal')) \n",
        "  model.add(K.layers.Dense(units=32, activation='relu', kernel_initializer='truncated_normal'))\n",
        "  model.add(K.layers.Dense(units=1, activation='sigmoid', kernel_initializer='truncated_normal'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bnhCoMHUYpni",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hparamsBatch = [64, 128, 256]\n",
        "hparamsEpoch = [250, 500, 1000]\n",
        "#hparamsOptimizer = ['RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "hparamsLR = [0.00001, 0.0001, 0.001, 0.01]\n",
        "#hparamsMomentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
        "#hparamsActivation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "#Defining the Range\n",
        "param_grid = dict(batch_size=hparamsBatch,\n",
        "                  epochs=hparamsEpoch,\n",
        "                  learn_rate=hparamsLR)\n",
        "\n",
        "grid = GridSearchCV(estimator=model, \n",
        "                    param_grid=param_grid,\n",
        "                    n_jobs=2,\n",
        "                    cv=3,\n",
        "                    scoring='accuracy',\n",
        "                    verbose=10)\n",
        "grid_result = grid.fit(X_train, Y_train)\n",
        "\n",
        "# Show the results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oOiTuEbyUMW9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "14614acf-20cc-4da9-d69e-12f0c664cb85"
      },
      "cell_type": "code",
      "source": [
        "#Creates a NN\n",
        "model = Sequential()\n",
        "#Input Layer\n",
        "model.add(K.layers.Dense(units=40, input_dim=40, activation='relu', kernel_initializer='truncated_normal')) \n",
        "#Hidden Layers\n",
        "model.add(K.layers.Dense(units=32, activation='relu', kernel_initializer='truncated_normal')) \n",
        "model.add(K.layers.Dense(units=32, activation='relu', kernel_initializer='truncated_normal'))\n",
        "#Output Layers\n",
        "model.add(K.layers.Dense(units=1, activation='sigmoid', kernel_initializer='truncated_normal'))\n",
        "\n",
        "simple_sgd = K.optimizers.Adam(lr=0.00001)  \n",
        "model.compile(loss='binary_crossentropy', optimizer=simple_sgd, metrics=['accuracy']) "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TA4leyXvYfp1",
        "colab_type": "code",
        "outputId": "826275a5-695f-4e2e-ee5c-650af719ad94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34085
        }
      },
      "cell_type": "code",
      "source": [
        "#Find out the size of each class so can change weighting\n",
        "trueWeight = len(Y_train[Y_train==False])\n",
        "falseWeight = len(Y_train[Y_train==True])\n",
        "\n",
        "history = model.fit(X_train, Y_train, batch_size=64, epochs=1000, validation_split=0.2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 54924 samples, validate on 13732 samples\n",
            "Epoch 1/1000\n",
            "54924/54924 [==============================] - 2s 35us/step - loss: 0.6689 - acc: 0.9492 - val_loss: 0.5487 - val_acc: 0.9519\n",
            "Epoch 2/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.5068 - acc: 0.9491 - val_loss: 0.4639 - val_acc: 0.9351\n",
            "Epoch 3/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.3778 - acc: 0.9482 - val_loss: 0.3097 - val_acc: 0.9519\n",
            "Epoch 4/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.2888 - acc: 0.9483 - val_loss: 0.2817 - val_acc: 0.9295\n",
            "Epoch 5/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.2616 - acc: 0.9485 - val_loss: 0.2503 - val_acc: 0.9519\n",
            "Epoch 6/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.2507 - acc: 0.9495 - val_loss: 0.2377 - val_acc: 0.9519\n",
            "Epoch 7/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.2423 - acc: 0.9489 - val_loss: 0.2314 - val_acc: 0.9519\n",
            "Epoch 8/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.2331 - acc: 0.9490 - val_loss: 0.2222 - val_acc: 0.9519\n",
            "Epoch 9/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.2246 - acc: 0.9494 - val_loss: 0.2156 - val_acc: 0.9519\n",
            "Epoch 10/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.2228 - acc: 0.9480 - val_loss: 0.2118 - val_acc: 0.9519\n",
            "Epoch 11/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.2131 - acc: 0.9497 - val_loss: 0.2062 - val_acc: 0.9518\n",
            "Epoch 12/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.2091 - acc: 0.9493 - val_loss: 0.2008 - val_acc: 0.9519\n",
            "Epoch 13/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.2051 - acc: 0.9493 - val_loss: 0.1996 - val_acc: 0.9515\n",
            "Epoch 14/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1988 - acc: 0.9491 - val_loss: 0.1911 - val_acc: 0.9520\n",
            "Epoch 15/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.1964 - acc: 0.9489 - val_loss: 0.1871 - val_acc: 0.9520\n",
            "Epoch 16/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1930 - acc: 0.9493 - val_loss: 0.1843 - val_acc: 0.9518\n",
            "Epoch 17/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1906 - acc: 0.9489 - val_loss: 0.1830 - val_acc: 0.9517\n",
            "Epoch 18/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1935 - acc: 0.9489 - val_loss: 0.1813 - val_acc: 0.9515\n",
            "Epoch 19/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1877 - acc: 0.9491 - val_loss: 0.1790 - val_acc: 0.9518\n",
            "Epoch 20/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.1903 - acc: 0.9487 - val_loss: 0.1834 - val_acc: 0.9522\n",
            "Epoch 21/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1891 - acc: 0.9492 - val_loss: 0.1810 - val_acc: 0.9508\n",
            "Epoch 22/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.1850 - acc: 0.9490 - val_loss: 0.1789 - val_acc: 0.9516\n",
            "Epoch 23/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1884 - acc: 0.9484 - val_loss: 0.1787 - val_acc: 0.9519\n",
            "Epoch 24/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.1856 - acc: 0.9492 - val_loss: 0.1796 - val_acc: 0.9517\n",
            "Epoch 25/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1849 - acc: 0.9490 - val_loss: 0.1833 - val_acc: 0.9479\n",
            "Epoch 26/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1870 - acc: 0.9480 - val_loss: 0.2023 - val_acc: 0.9413\n",
            "Epoch 27/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.1846 - acc: 0.9491 - val_loss: 0.1770 - val_acc: 0.9504\n",
            "Epoch 28/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.1851 - acc: 0.9491 - val_loss: 0.1793 - val_acc: 0.9515\n",
            "Epoch 29/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1868 - acc: 0.9485 - val_loss: 0.1773 - val_acc: 0.9519\n",
            "Epoch 30/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1807 - acc: 0.9499 - val_loss: 0.1727 - val_acc: 0.9511\n",
            "Epoch 31/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1827 - acc: 0.9490 - val_loss: 0.1769 - val_acc: 0.9510\n",
            "Epoch 32/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1857 - acc: 0.9485 - val_loss: 0.1714 - val_acc: 0.9512\n",
            "Epoch 33/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1818 - acc: 0.9490 - val_loss: 0.1938 - val_acc: 0.9520\n",
            "Epoch 34/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1819 - acc: 0.9491 - val_loss: 0.1776 - val_acc: 0.9515\n",
            "Epoch 35/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1793 - acc: 0.9492 - val_loss: 0.1737 - val_acc: 0.9516\n",
            "Epoch 36/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1785 - acc: 0.9492 - val_loss: 0.1735 - val_acc: 0.9515\n",
            "Epoch 37/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.1801 - acc: 0.9493 - val_loss: 0.1821 - val_acc: 0.9471\n",
            "Epoch 38/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1784 - acc: 0.9492 - val_loss: 0.1715 - val_acc: 0.9516\n",
            "Epoch 39/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1795 - acc: 0.9495 - val_loss: 0.1747 - val_acc: 0.9519\n",
            "Epoch 40/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1793 - acc: 0.9490 - val_loss: 0.1713 - val_acc: 0.9514\n",
            "Epoch 41/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1778 - acc: 0.9497 - val_loss: 0.1699 - val_acc: 0.9513\n",
            "Epoch 42/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1804 - acc: 0.9491 - val_loss: 0.1802 - val_acc: 0.9520\n",
            "Epoch 43/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1783 - acc: 0.9492 - val_loss: 0.1893 - val_acc: 0.9423\n",
            "Epoch 44/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1806 - acc: 0.9490 - val_loss: 0.1678 - val_acc: 0.9516\n",
            "Epoch 45/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1792 - acc: 0.9489 - val_loss: 0.1741 - val_acc: 0.9514\n",
            "Epoch 46/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1777 - acc: 0.9492 - val_loss: 0.1825 - val_acc: 0.9457\n",
            "Epoch 47/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1768 - acc: 0.9495 - val_loss: 0.1727 - val_acc: 0.9519\n",
            "Epoch 48/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1774 - acc: 0.9493 - val_loss: 0.1733 - val_acc: 0.9517\n",
            "Epoch 49/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.1779 - acc: 0.9487 - val_loss: 0.1711 - val_acc: 0.9515\n",
            "Epoch 50/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1758 - acc: 0.9494 - val_loss: 0.1698 - val_acc: 0.9514\n",
            "Epoch 51/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1758 - acc: 0.9494 - val_loss: 0.1788 - val_acc: 0.9519\n",
            "Epoch 52/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1783 - acc: 0.9491 - val_loss: 0.1664 - val_acc: 0.9516\n",
            "Epoch 53/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1753 - acc: 0.9494 - val_loss: 0.1703 - val_acc: 0.9510\n",
            "Epoch 54/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.1758 - acc: 0.9490 - val_loss: 0.1682 - val_acc: 0.9508\n",
            "Epoch 55/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1741 - acc: 0.9489 - val_loss: 0.1883 - val_acc: 0.9520\n",
            "Epoch 56/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1742 - acc: 0.9497 - val_loss: 0.1761 - val_acc: 0.9484\n",
            "Epoch 57/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.1738 - acc: 0.9493 - val_loss: 0.1910 - val_acc: 0.9520\n",
            "Epoch 58/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1767 - acc: 0.9491 - val_loss: 0.1654 - val_acc: 0.9518\n",
            "Epoch 59/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1746 - acc: 0.9491 - val_loss: 0.1691 - val_acc: 0.9521\n",
            "Epoch 60/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.1738 - acc: 0.9491 - val_loss: 0.1652 - val_acc: 0.9518\n",
            "Epoch 61/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1729 - acc: 0.9491 - val_loss: 0.1718 - val_acc: 0.9519\n",
            "Epoch 62/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1743 - acc: 0.9498 - val_loss: 0.1662 - val_acc: 0.9516\n",
            "Epoch 63/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1751 - acc: 0.9489 - val_loss: 0.1639 - val_acc: 0.9519\n",
            "Epoch 64/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.1722 - acc: 0.9498 - val_loss: 0.1753 - val_acc: 0.9519\n",
            "Epoch 65/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1740 - acc: 0.9494 - val_loss: 0.1672 - val_acc: 0.9521\n",
            "Epoch 66/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1739 - acc: 0.9493 - val_loss: 0.1687 - val_acc: 0.9520\n",
            "Epoch 67/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1729 - acc: 0.9499 - val_loss: 0.1684 - val_acc: 0.9505\n",
            "Epoch 68/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1718 - acc: 0.9494 - val_loss: 0.1642 - val_acc: 0.9518\n",
            "Epoch 69/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1732 - acc: 0.9491 - val_loss: 0.1623 - val_acc: 0.9519\n",
            "Epoch 70/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1729 - acc: 0.9489 - val_loss: 0.1628 - val_acc: 0.9519\n",
            "Epoch 71/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1729 - acc: 0.9490 - val_loss: 0.1702 - val_acc: 0.9519\n",
            "Epoch 72/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1720 - acc: 0.9490 - val_loss: 0.1662 - val_acc: 0.9506\n",
            "Epoch 73/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1694 - acc: 0.9497 - val_loss: 0.1629 - val_acc: 0.9519\n",
            "Epoch 74/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1695 - acc: 0.9493 - val_loss: 0.1625 - val_acc: 0.9518\n",
            "Epoch 75/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1682 - acc: 0.9493 - val_loss: 0.2501 - val_acc: 0.9203\n",
            "Epoch 76/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1709 - acc: 0.9490 - val_loss: 0.1631 - val_acc: 0.9520\n",
            "Epoch 77/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1711 - acc: 0.9483 - val_loss: 0.1787 - val_acc: 0.9519\n",
            "Epoch 78/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1720 - acc: 0.9485 - val_loss: 0.1802 - val_acc: 0.9426\n",
            "Epoch 79/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1671 - acc: 0.9498 - val_loss: 0.1615 - val_acc: 0.9520\n",
            "Epoch 80/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1683 - acc: 0.9493 - val_loss: 0.1610 - val_acc: 0.9519\n",
            "Epoch 81/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1685 - acc: 0.9494 - val_loss: 0.1650 - val_acc: 0.9524\n",
            "Epoch 82/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1693 - acc: 0.9491 - val_loss: 0.1657 - val_acc: 0.9520\n",
            "Epoch 83/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1691 - acc: 0.9498 - val_loss: 0.1834 - val_acc: 0.9522\n",
            "Epoch 84/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1686 - acc: 0.9494 - val_loss: 0.1733 - val_acc: 0.9449\n",
            "Epoch 85/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1666 - acc: 0.9498 - val_loss: 0.1747 - val_acc: 0.9521\n",
            "Epoch 86/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1668 - acc: 0.9497 - val_loss: 0.1646 - val_acc: 0.9521\n",
            "Epoch 87/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1665 - acc: 0.9491 - val_loss: 0.1617 - val_acc: 0.9506\n",
            "Epoch 88/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1654 - acc: 0.9493 - val_loss: 0.1580 - val_acc: 0.9522\n",
            "Epoch 89/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1682 - acc: 0.9492 - val_loss: 0.1582 - val_acc: 0.9522\n",
            "Epoch 90/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1685 - acc: 0.9489 - val_loss: 0.1593 - val_acc: 0.9516\n",
            "Epoch 91/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1655 - acc: 0.9494 - val_loss: 0.1632 - val_acc: 0.9496\n",
            "Epoch 92/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1663 - acc: 0.9495 - val_loss: 0.1583 - val_acc: 0.9522\n",
            "Epoch 93/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.1689 - acc: 0.9488 - val_loss: 0.1632 - val_acc: 0.9495\n",
            "Epoch 94/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.1654 - acc: 0.9498 - val_loss: 0.1584 - val_acc: 0.9521\n",
            "Epoch 95/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1678 - acc: 0.9501 - val_loss: 0.1584 - val_acc: 0.9519\n",
            "Epoch 96/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1671 - acc: 0.9496 - val_loss: 0.1594 - val_acc: 0.9524\n",
            "Epoch 97/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1642 - acc: 0.9500 - val_loss: 0.1576 - val_acc: 0.9523\n",
            "Epoch 98/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1642 - acc: 0.9496 - val_loss: 0.1563 - val_acc: 0.9520\n",
            "Epoch 99/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.1643 - acc: 0.9496 - val_loss: 0.1593 - val_acc: 0.9523\n",
            "Epoch 100/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.1638 - acc: 0.9500 - val_loss: 0.1638 - val_acc: 0.9522\n",
            "Epoch 101/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.1653 - acc: 0.9493 - val_loss: 0.1631 - val_acc: 0.9521\n",
            "Epoch 102/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.1614 - acc: 0.9502 - val_loss: 0.1610 - val_acc: 0.9521\n",
            "Epoch 103/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1635 - acc: 0.9500 - val_loss: 0.1881 - val_acc: 0.9425\n",
            "Epoch 104/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1651 - acc: 0.9495 - val_loss: 0.1609 - val_acc: 0.9522\n",
            "Epoch 105/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1651 - acc: 0.9496 - val_loss: 0.1575 - val_acc: 0.9524\n",
            "Epoch 106/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1626 - acc: 0.9503 - val_loss: 0.1631 - val_acc: 0.9519\n",
            "Epoch 107/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1647 - acc: 0.9500 - val_loss: 0.1565 - val_acc: 0.9524\n",
            "Epoch 108/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1632 - acc: 0.9501 - val_loss: 0.1568 - val_acc: 0.9524\n",
            "Epoch 109/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1608 - acc: 0.9502 - val_loss: 0.1570 - val_acc: 0.9522\n",
            "Epoch 110/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.1619 - acc: 0.9494 - val_loss: 0.1542 - val_acc: 0.9524\n",
            "Epoch 111/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1576 - acc: 0.9502 - val_loss: 0.1549 - val_acc: 0.9519\n",
            "Epoch 112/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1596 - acc: 0.9497 - val_loss: 0.1519 - val_acc: 0.9524\n",
            "Epoch 113/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.1572 - acc: 0.9501 - val_loss: 0.1547 - val_acc: 0.9514\n",
            "Epoch 114/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1615 - acc: 0.9495 - val_loss: 0.1523 - val_acc: 0.9531\n",
            "Epoch 115/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.1637 - acc: 0.9489 - val_loss: 0.1855 - val_acc: 0.9520\n",
            "Epoch 116/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.1577 - acc: 0.9504 - val_loss: 0.1526 - val_acc: 0.9524\n",
            "Epoch 117/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1557 - acc: 0.9500 - val_loss: 0.1538 - val_acc: 0.9525\n",
            "Epoch 118/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1566 - acc: 0.9503 - val_loss: 0.1496 - val_acc: 0.9525\n",
            "Epoch 119/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1587 - acc: 0.9503 - val_loss: 0.1531 - val_acc: 0.9511\n",
            "Epoch 120/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1567 - acc: 0.9506 - val_loss: 0.1748 - val_acc: 0.9426\n",
            "Epoch 121/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1552 - acc: 0.9499 - val_loss: 0.1468 - val_acc: 0.9530\n",
            "Epoch 122/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1567 - acc: 0.9503 - val_loss: 0.1545 - val_acc: 0.9527\n",
            "Epoch 123/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1596 - acc: 0.9493 - val_loss: 0.1533 - val_acc: 0.9522\n",
            "Epoch 124/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1544 - acc: 0.9503 - val_loss: 0.1565 - val_acc: 0.9527\n",
            "Epoch 125/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.1564 - acc: 0.9499 - val_loss: 0.1487 - val_acc: 0.9531\n",
            "Epoch 126/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1549 - acc: 0.9506 - val_loss: 0.1531 - val_acc: 0.9516\n",
            "Epoch 127/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1506 - acc: 0.9510 - val_loss: 0.1825 - val_acc: 0.9382\n",
            "Epoch 128/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1512 - acc: 0.9513 - val_loss: 0.1497 - val_acc: 0.9532\n",
            "Epoch 129/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1507 - acc: 0.9512 - val_loss: 0.1491 - val_acc: 0.9513\n",
            "Epoch 130/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1529 - acc: 0.9503 - val_loss: 0.1433 - val_acc: 0.9532\n",
            "Epoch 131/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.1516 - acc: 0.9506 - val_loss: 0.1424 - val_acc: 0.9537\n",
            "Epoch 132/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1489 - acc: 0.9511 - val_loss: 0.1459 - val_acc: 0.9527\n",
            "Epoch 133/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1511 - acc: 0.9511 - val_loss: 0.1442 - val_acc: 0.9535\n",
            "Epoch 134/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1492 - acc: 0.9505 - val_loss: 0.1424 - val_acc: 0.9538\n",
            "Epoch 135/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1520 - acc: 0.9506 - val_loss: 0.1677 - val_acc: 0.9449\n",
            "Epoch 136/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1524 - acc: 0.9504 - val_loss: 0.1426 - val_acc: 0.9538\n",
            "Epoch 137/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1487 - acc: 0.9519 - val_loss: 0.1417 - val_acc: 0.9540\n",
            "Epoch 138/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1510 - acc: 0.9507 - val_loss: 0.1445 - val_acc: 0.9526\n",
            "Epoch 139/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1475 - acc: 0.9511 - val_loss: 0.1431 - val_acc: 0.9530\n",
            "Epoch 140/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1496 - acc: 0.9510 - val_loss: 0.1492 - val_acc: 0.9535\n",
            "Epoch 141/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1479 - acc: 0.9516 - val_loss: 0.1409 - val_acc: 0.9546\n",
            "Epoch 142/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1454 - acc: 0.9521 - val_loss: 0.1375 - val_acc: 0.9552\n",
            "Epoch 143/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1483 - acc: 0.9516 - val_loss: 0.1455 - val_acc: 0.9540\n",
            "Epoch 144/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1458 - acc: 0.9519 - val_loss: 0.1370 - val_acc: 0.9540\n",
            "Epoch 145/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1420 - acc: 0.9523 - val_loss: 0.1447 - val_acc: 0.9541\n",
            "Epoch 146/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1440 - acc: 0.9520 - val_loss: 0.1618 - val_acc: 0.9528\n",
            "Epoch 147/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.1456 - acc: 0.9520 - val_loss: 0.1475 - val_acc: 0.9535\n",
            "Epoch 148/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1402 - acc: 0.9517 - val_loss: 0.1370 - val_acc: 0.9535\n",
            "Epoch 149/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1436 - acc: 0.9511 - val_loss: 0.1656 - val_acc: 0.9529\n",
            "Epoch 150/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1419 - acc: 0.9520 - val_loss: 0.1392 - val_acc: 0.9533\n",
            "Epoch 151/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.1397 - acc: 0.9521 - val_loss: 0.1524 - val_acc: 0.9531\n",
            "Epoch 152/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1416 - acc: 0.9522 - val_loss: 0.1394 - val_acc: 0.9540\n",
            "Epoch 153/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1354 - acc: 0.9530 - val_loss: 0.1442 - val_acc: 0.9550\n",
            "Epoch 154/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1353 - acc: 0.9530 - val_loss: 0.1499 - val_acc: 0.9538\n",
            "Epoch 155/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1347 - acc: 0.9533 - val_loss: 0.1296 - val_acc: 0.9551\n",
            "Epoch 156/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1354 - acc: 0.9528 - val_loss: 0.1619 - val_acc: 0.9538\n",
            "Epoch 157/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.1357 - acc: 0.9531 - val_loss: 0.1606 - val_acc: 0.9526\n",
            "Epoch 158/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1324 - acc: 0.9532 - val_loss: 0.1321 - val_acc: 0.9540\n",
            "Epoch 159/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1296 - acc: 0.9532 - val_loss: 0.1382 - val_acc: 0.9554\n",
            "Epoch 160/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1299 - acc: 0.9531 - val_loss: 0.1226 - val_acc: 0.9557\n",
            "Epoch 161/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.1282 - acc: 0.9541 - val_loss: 0.1200 - val_acc: 0.9565\n",
            "Epoch 162/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1304 - acc: 0.9531 - val_loss: 0.1215 - val_acc: 0.9564\n",
            "Epoch 163/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1282 - acc: 0.9536 - val_loss: 0.1244 - val_acc: 0.9555\n",
            "Epoch 164/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.1256 - acc: 0.9549 - val_loss: 0.1225 - val_acc: 0.9568\n",
            "Epoch 165/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.1242 - acc: 0.9546 - val_loss: 0.1181 - val_acc: 0.9573\n",
            "Epoch 166/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.1281 - acc: 0.9548 - val_loss: 0.1672 - val_acc: 0.9544\n",
            "Epoch 167/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1204 - acc: 0.9554 - val_loss: 0.1125 - val_acc: 0.9582\n",
            "Epoch 168/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1201 - acc: 0.9556 - val_loss: 0.1115 - val_acc: 0.9582\n",
            "Epoch 169/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1181 - acc: 0.9567 - val_loss: 0.1116 - val_acc: 0.9582\n",
            "Epoch 170/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1186 - acc: 0.9561 - val_loss: 0.1097 - val_acc: 0.9589\n",
            "Epoch 171/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.1184 - acc: 0.9556 - val_loss: 0.1687 - val_acc: 0.9554\n",
            "Epoch 172/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1129 - acc: 0.9566 - val_loss: 0.1053 - val_acc: 0.9597\n",
            "Epoch 173/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1134 - acc: 0.9579 - val_loss: 0.1034 - val_acc: 0.9600\n",
            "Epoch 174/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1098 - acc: 0.9580 - val_loss: 0.1011 - val_acc: 0.9603\n",
            "Epoch 175/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1126 - acc: 0.9571 - val_loss: 0.1072 - val_acc: 0.9599\n",
            "Epoch 176/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1072 - acc: 0.9588 - val_loss: 0.1044 - val_acc: 0.9612\n",
            "Epoch 177/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.1055 - acc: 0.9590 - val_loss: 0.0977 - val_acc: 0.9608\n",
            "Epoch 178/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1059 - acc: 0.9596 - val_loss: 0.1047 - val_acc: 0.9608\n",
            "Epoch 179/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1129 - acc: 0.9582 - val_loss: 0.1038 - val_acc: 0.9599\n",
            "Epoch 180/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1054 - acc: 0.9591 - val_loss: 0.0987 - val_acc: 0.9596\n",
            "Epoch 181/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1010 - acc: 0.9606 - val_loss: 0.0927 - val_acc: 0.9633\n",
            "Epoch 182/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0951 - acc: 0.9624 - val_loss: 0.1048 - val_acc: 0.9626\n",
            "Epoch 183/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0996 - acc: 0.9611 - val_loss: 0.0926 - val_acc: 0.9661\n",
            "Epoch 184/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0938 - acc: 0.9625 - val_loss: 0.1604 - val_acc: 0.9242\n",
            "Epoch 185/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1007 - acc: 0.9609 - val_loss: 0.0890 - val_acc: 0.9634\n",
            "Epoch 186/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1014 - acc: 0.9612 - val_loss: 0.1056 - val_acc: 0.9585\n",
            "Epoch 187/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0987 - acc: 0.9632 - val_loss: 0.0916 - val_acc: 0.9606\n",
            "Epoch 188/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0915 - acc: 0.9649 - val_loss: 0.0938 - val_acc: 0.9621\n",
            "Epoch 189/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0952 - acc: 0.9633 - val_loss: 0.0801 - val_acc: 0.9650\n",
            "Epoch 190/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0929 - acc: 0.9642 - val_loss: 0.0800 - val_acc: 0.9656\n",
            "Epoch 191/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0880 - acc: 0.9652 - val_loss: 0.0783 - val_acc: 0.9701\n",
            "Epoch 192/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0865 - acc: 0.9665 - val_loss: 0.1055 - val_acc: 0.9610\n",
            "Epoch 193/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0858 - acc: 0.9669 - val_loss: 0.0960 - val_acc: 0.9632\n",
            "Epoch 194/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0890 - acc: 0.9660 - val_loss: 0.0872 - val_acc: 0.9709\n",
            "Epoch 195/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0862 - acc: 0.9671 - val_loss: 0.0883 - val_acc: 0.9728\n",
            "Epoch 196/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0873 - acc: 0.9654 - val_loss: 0.0730 - val_acc: 0.9693\n",
            "Epoch 197/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0774 - acc: 0.9689 - val_loss: 0.0672 - val_acc: 0.9707\n",
            "Epoch 198/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0791 - acc: 0.9687 - val_loss: 0.0678 - val_acc: 0.9702\n",
            "Epoch 199/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0749 - acc: 0.9693 - val_loss: 0.0712 - val_acc: 0.9685\n",
            "Epoch 200/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0760 - acc: 0.9701 - val_loss: 0.0915 - val_acc: 0.9666\n",
            "Epoch 201/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0715 - acc: 0.9723 - val_loss: 0.0631 - val_acc: 0.9777\n",
            "Epoch 202/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0766 - acc: 0.9712 - val_loss: 0.0656 - val_acc: 0.9782\n",
            "Epoch 203/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0716 - acc: 0.9731 - val_loss: 0.0586 - val_acc: 0.9758\n",
            "Epoch 204/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0776 - acc: 0.9715 - val_loss: 0.0592 - val_acc: 0.9755\n",
            "Epoch 205/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0686 - acc: 0.9748 - val_loss: 0.0977 - val_acc: 0.9696\n",
            "Epoch 206/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0640 - acc: 0.9760 - val_loss: 0.0558 - val_acc: 0.9800\n",
            "Epoch 207/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0704 - acc: 0.9752 - val_loss: 0.0698 - val_acc: 0.9747\n",
            "Epoch 208/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0640 - acc: 0.9778 - val_loss: 0.0568 - val_acc: 0.9784\n",
            "Epoch 209/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0646 - acc: 0.9781 - val_loss: 0.0549 - val_acc: 0.9828\n",
            "Epoch 210/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0633 - acc: 0.9788 - val_loss: 0.0534 - val_acc: 0.9828\n",
            "Epoch 211/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0616 - acc: 0.9799 - val_loss: 0.0465 - val_acc: 0.9865\n",
            "Epoch 212/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0661 - acc: 0.9781 - val_loss: 0.0550 - val_acc: 0.9806\n",
            "Epoch 213/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0618 - acc: 0.9795 - val_loss: 0.0640 - val_acc: 0.9779\n",
            "Epoch 214/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0580 - acc: 0.9810 - val_loss: 0.0491 - val_acc: 0.9886\n",
            "Epoch 215/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0613 - acc: 0.9821 - val_loss: 0.0729 - val_acc: 0.9816\n",
            "Epoch 216/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0634 - acc: 0.9822 - val_loss: 0.0436 - val_acc: 0.9874\n",
            "Epoch 217/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0652 - acc: 0.9807 - val_loss: 0.0490 - val_acc: 0.9832\n",
            "Epoch 218/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0615 - acc: 0.9829 - val_loss: 0.0673 - val_acc: 0.9813\n",
            "Epoch 219/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0615 - acc: 0.9828 - val_loss: 0.0620 - val_acc: 0.9854\n",
            "Epoch 220/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0538 - acc: 0.9846 - val_loss: 0.0477 - val_acc: 0.9857\n",
            "Epoch 221/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0609 - acc: 0.9836 - val_loss: 0.0549 - val_acc: 0.9830\n",
            "Epoch 222/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0632 - acc: 0.9830 - val_loss: 0.0439 - val_acc: 0.9886\n",
            "Epoch 223/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0665 - acc: 0.9841 - val_loss: 0.0417 - val_acc: 0.9921\n",
            "Epoch 224/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0550 - acc: 0.9860 - val_loss: 0.0411 - val_acc: 0.9913\n",
            "Epoch 225/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0646 - acc: 0.9834 - val_loss: 0.0745 - val_acc: 0.9748\n",
            "Epoch 226/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0604 - acc: 0.9841 - val_loss: 0.0867 - val_acc: 0.9806\n",
            "Epoch 227/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0558 - acc: 0.9863 - val_loss: 0.1542 - val_acc: 0.9730\n",
            "Epoch 228/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0534 - acc: 0.9864 - val_loss: 0.0343 - val_acc: 0.9903\n",
            "Epoch 229/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0563 - acc: 0.9867 - val_loss: 0.0348 - val_acc: 0.9905\n",
            "Epoch 230/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0532 - acc: 0.9858 - val_loss: 0.0544 - val_acc: 0.9846\n",
            "Epoch 231/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0492 - acc: 0.9877 - val_loss: 0.0409 - val_acc: 0.9883\n",
            "Epoch 232/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0605 - acc: 0.9862 - val_loss: 0.0444 - val_acc: 0.9901\n",
            "Epoch 233/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0512 - acc: 0.9880 - val_loss: 0.0316 - val_acc: 0.9935\n",
            "Epoch 234/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0531 - acc: 0.9876 - val_loss: 0.0373 - val_acc: 0.9897\n",
            "Epoch 235/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0500 - acc: 0.9876 - val_loss: 0.0436 - val_acc: 0.9921\n",
            "Epoch 236/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0567 - acc: 0.9865 - val_loss: 0.1043 - val_acc: 0.9787\n",
            "Epoch 237/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0536 - acc: 0.9876 - val_loss: 0.0487 - val_acc: 0.9886\n",
            "Epoch 238/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0518 - acc: 0.9879 - val_loss: 0.0357 - val_acc: 0.9909\n",
            "Epoch 239/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0550 - acc: 0.9875 - val_loss: 0.0441 - val_acc: 0.9863\n",
            "Epoch 240/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0531 - acc: 0.9878 - val_loss: 0.0503 - val_acc: 0.9848\n",
            "Epoch 241/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0538 - acc: 0.9888 - val_loss: 0.0372 - val_acc: 0.9942\n",
            "Epoch 242/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0701 - acc: 0.9872 - val_loss: 0.0329 - val_acc: 0.9929\n",
            "Epoch 243/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0703 - acc: 0.9868 - val_loss: 0.0625 - val_acc: 0.9871\n",
            "Epoch 244/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0528 - acc: 0.9887 - val_loss: 0.0358 - val_acc: 0.9931\n",
            "Epoch 245/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0497 - acc: 0.9896 - val_loss: 0.0439 - val_acc: 0.9940\n",
            "Epoch 246/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0516 - acc: 0.9886 - val_loss: 0.0454 - val_acc: 0.9934\n",
            "Epoch 247/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0455 - acc: 0.9898 - val_loss: 0.0307 - val_acc: 0.9941\n",
            "Epoch 248/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0484 - acc: 0.9891 - val_loss: 0.0807 - val_acc: 0.9801\n",
            "Epoch 249/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0456 - acc: 0.9897 - val_loss: 0.1183 - val_acc: 0.9806\n",
            "Epoch 250/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0514 - acc: 0.9887 - val_loss: 0.1858 - val_acc: 0.9763\n",
            "Epoch 251/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0518 - acc: 0.9882 - val_loss: 0.0379 - val_acc: 0.9913\n",
            "Epoch 252/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0477 - acc: 0.9888 - val_loss: 0.0406 - val_acc: 0.9938\n",
            "Epoch 253/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0429 - acc: 0.9898 - val_loss: 0.0775 - val_acc: 0.9766\n",
            "Epoch 254/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0466 - acc: 0.9887 - val_loss: 0.0320 - val_acc: 0.9956\n",
            "Epoch 255/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0559 - acc: 0.9871 - val_loss: 0.0363 - val_acc: 0.9947\n",
            "Epoch 256/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0442 - acc: 0.9899 - val_loss: 0.0389 - val_acc: 0.9913\n",
            "Epoch 257/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0556 - acc: 0.9875 - val_loss: 0.0799 - val_acc: 0.9775\n",
            "Epoch 258/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0467 - acc: 0.9892 - val_loss: 0.0458 - val_acc: 0.9913\n",
            "Epoch 259/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0415 - acc: 0.9900 - val_loss: 0.0265 - val_acc: 0.9937\n",
            "Epoch 260/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0516 - acc: 0.9884 - val_loss: 0.0240 - val_acc: 0.9950\n",
            "Epoch 261/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0553 - acc: 0.9885 - val_loss: 0.0529 - val_acc: 0.9891\n",
            "Epoch 262/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0514 - acc: 0.9887 - val_loss: 0.0277 - val_acc: 0.9930\n",
            "Epoch 263/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0456 - acc: 0.9895 - val_loss: 0.0391 - val_acc: 0.9902\n",
            "Epoch 264/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0407 - acc: 0.9906 - val_loss: 0.0714 - val_acc: 0.9786\n",
            "Epoch 265/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0434 - acc: 0.9895 - val_loss: 0.0323 - val_acc: 0.9934\n",
            "Epoch 266/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0535 - acc: 0.9883 - val_loss: 0.0909 - val_acc: 0.9753\n",
            "Epoch 267/1000\n",
            "54924/54924 [==============================] - 2s 30us/step - loss: 0.0452 - acc: 0.9896 - val_loss: 0.2721 - val_acc: 0.9723\n",
            "Epoch 268/1000\n",
            "54924/54924 [==============================] - 2s 30us/step - loss: 0.0479 - acc: 0.9890 - val_loss: 0.0467 - val_acc: 0.9896\n",
            "Epoch 269/1000\n",
            "54924/54924 [==============================] - 2s 30us/step - loss: 0.0484 - acc: 0.9885 - val_loss: 0.0284 - val_acc: 0.9921\n",
            "Epoch 270/1000\n",
            "54924/54924 [==============================] - 2s 30us/step - loss: 0.0526 - acc: 0.9871 - val_loss: 0.0449 - val_acc: 0.9881\n",
            "Epoch 271/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0428 - acc: 0.9896 - val_loss: 0.0367 - val_acc: 0.9905\n",
            "Epoch 272/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0427 - acc: 0.9906 - val_loss: 0.0366 - val_acc: 0.9910\n",
            "Epoch 273/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0469 - acc: 0.9891 - val_loss: 0.0446 - val_acc: 0.9877\n",
            "Epoch 274/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0465 - acc: 0.9898 - val_loss: 0.0471 - val_acc: 0.9899\n",
            "Epoch 275/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0458 - acc: 0.9903 - val_loss: 0.0267 - val_acc: 0.9955\n",
            "Epoch 276/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0449 - acc: 0.9902 - val_loss: 0.0236 - val_acc: 0.9949\n",
            "Epoch 277/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0530 - acc: 0.9890 - val_loss: 0.0499 - val_acc: 0.9888\n",
            "Epoch 278/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0587 - acc: 0.9884 - val_loss: 0.0801 - val_acc: 0.9785\n",
            "Epoch 279/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0462 - acc: 0.9891 - val_loss: 0.0242 - val_acc: 0.9961\n",
            "Epoch 280/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0476 - acc: 0.9913 - val_loss: 0.0233 - val_acc: 0.9956\n",
            "Epoch 281/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0462 - acc: 0.9898 - val_loss: 0.0597 - val_acc: 0.9870\n",
            "Epoch 282/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0424 - acc: 0.9908 - val_loss: 0.0233 - val_acc: 0.9948\n",
            "Epoch 283/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0389 - acc: 0.9907 - val_loss: 0.0246 - val_acc: 0.9943\n",
            "Epoch 284/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0540 - acc: 0.9891 - val_loss: 0.0597 - val_acc: 0.9867\n",
            "Epoch 285/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0380 - acc: 0.9927 - val_loss: 0.0837 - val_acc: 0.9804\n",
            "Epoch 286/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0463 - acc: 0.9900 - val_loss: 0.0830 - val_acc: 0.9830\n",
            "Epoch 287/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0416 - acc: 0.9903 - val_loss: 0.0265 - val_acc: 0.9933\n",
            "Epoch 288/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0395 - acc: 0.9904 - val_loss: 0.0329 - val_acc: 0.9923\n",
            "Epoch 289/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0495 - acc: 0.9900 - val_loss: 0.0203 - val_acc: 0.9963\n",
            "Epoch 290/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0468 - acc: 0.9904 - val_loss: 0.0377 - val_acc: 0.9924\n",
            "Epoch 291/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0557 - acc: 0.9897 - val_loss: 0.1734 - val_acc: 0.9471\n",
            "Epoch 292/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0413 - acc: 0.9901 - val_loss: 0.0319 - val_acc: 0.9921\n",
            "Epoch 293/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0417 - acc: 0.9914 - val_loss: 0.0375 - val_acc: 0.9918\n",
            "Epoch 294/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0521 - acc: 0.9887 - val_loss: 0.0281 - val_acc: 0.9924\n",
            "Epoch 295/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0414 - acc: 0.9907 - val_loss: 0.0289 - val_acc: 0.9967\n",
            "Epoch 296/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0395 - acc: 0.9904 - val_loss: 0.0352 - val_acc: 0.9922\n",
            "Epoch 297/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0433 - acc: 0.9905 - val_loss: 0.0246 - val_acc: 0.9950\n",
            "Epoch 298/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0427 - acc: 0.9905 - val_loss: 0.0267 - val_acc: 0.9945\n",
            "Epoch 299/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0409 - acc: 0.9913 - val_loss: 0.0774 - val_acc: 0.9815\n",
            "Epoch 300/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0396 - acc: 0.9915 - val_loss: 0.1024 - val_acc: 0.9789\n",
            "Epoch 301/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0488 - acc: 0.9889 - val_loss: 0.0406 - val_acc: 0.9917\n",
            "Epoch 302/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0427 - acc: 0.9912 - val_loss: 0.0188 - val_acc: 0.9963\n",
            "Epoch 303/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0484 - acc: 0.9895 - val_loss: 0.0751 - val_acc: 0.9849\n",
            "Epoch 304/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0402 - acc: 0.9899 - val_loss: 0.0372 - val_acc: 0.9902\n",
            "Epoch 305/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0377 - acc: 0.9914 - val_loss: 0.0246 - val_acc: 0.9939\n",
            "Epoch 306/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0405 - acc: 0.9911 - val_loss: 0.0275 - val_acc: 0.9947\n",
            "Epoch 307/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0448 - acc: 0.9903 - val_loss: 0.0244 - val_acc: 0.9946\n",
            "Epoch 308/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0364 - acc: 0.9910 - val_loss: 0.0368 - val_acc: 0.9913\n",
            "Epoch 309/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0424 - acc: 0.9901 - val_loss: 0.0431 - val_acc: 0.9897\n",
            "Epoch 310/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0449 - acc: 0.9892 - val_loss: 0.0323 - val_acc: 0.9942\n",
            "Epoch 311/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0575 - acc: 0.9903 - val_loss: 0.0408 - val_acc: 0.9938\n",
            "Epoch 312/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0379 - acc: 0.9913 - val_loss: 0.0268 - val_acc: 0.9939\n",
            "Epoch 313/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0399 - acc: 0.9912 - val_loss: 0.0439 - val_acc: 0.9902\n",
            "Epoch 314/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0345 - acc: 0.9917 - val_loss: 0.0305 - val_acc: 0.9923\n",
            "Epoch 315/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0326 - acc: 0.9925 - val_loss: 0.0737 - val_acc: 0.9876\n",
            "Epoch 316/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0481 - acc: 0.9904 - val_loss: 0.0269 - val_acc: 0.9940\n",
            "Epoch 317/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0469 - acc: 0.9908 - val_loss: 0.0255 - val_acc: 0.9944\n",
            "Epoch 318/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0561 - acc: 0.9888 - val_loss: 0.0413 - val_acc: 0.9889\n",
            "Epoch 319/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0389 - acc: 0.9910 - val_loss: 0.0354 - val_acc: 0.9924\n",
            "Epoch 320/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0423 - acc: 0.9901 - val_loss: 0.0505 - val_acc: 0.9885\n",
            "Epoch 321/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0326 - acc: 0.9920 - val_loss: 0.0200 - val_acc: 0.9952\n",
            "Epoch 322/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0351 - acc: 0.9914 - val_loss: 0.0229 - val_acc: 0.9936\n",
            "Epoch 323/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0380 - acc: 0.9922 - val_loss: 0.0264 - val_acc: 0.9937\n",
            "Epoch 324/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0463 - acc: 0.9911 - val_loss: 0.0247 - val_acc: 0.9935\n",
            "Epoch 325/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0342 - acc: 0.9917 - val_loss: 0.0482 - val_acc: 0.9903\n",
            "Epoch 326/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0385 - acc: 0.9909 - val_loss: 0.0237 - val_acc: 0.9968\n",
            "Epoch 327/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0419 - acc: 0.9909 - val_loss: 0.0396 - val_acc: 0.9907\n",
            "Epoch 328/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0401 - acc: 0.9901 - val_loss: 0.0202 - val_acc: 0.9971\n",
            "Epoch 329/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0352 - acc: 0.9914 - val_loss: 0.1179 - val_acc: 0.9658\n",
            "Epoch 330/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0362 - acc: 0.9916 - val_loss: 0.0308 - val_acc: 0.9914\n",
            "Epoch 331/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0328 - acc: 0.9914 - val_loss: 0.0228 - val_acc: 0.9956\n",
            "Epoch 332/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0540 - acc: 0.9897 - val_loss: 0.0310 - val_acc: 0.9929\n",
            "Epoch 333/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0551 - acc: 0.9911 - val_loss: 0.0984 - val_acc: 0.9857\n",
            "Epoch 334/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0511 - acc: 0.9905 - val_loss: 0.0231 - val_acc: 0.9969\n",
            "Epoch 335/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0520 - acc: 0.9921 - val_loss: 0.0221 - val_acc: 0.9972\n",
            "Epoch 336/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0392 - acc: 0.9927 - val_loss: 0.0338 - val_acc: 0.9929\n",
            "Epoch 337/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0356 - acc: 0.9923 - val_loss: 0.0185 - val_acc: 0.9958\n",
            "Epoch 338/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0325 - acc: 0.9931 - val_loss: 0.0605 - val_acc: 0.9891\n",
            "Epoch 339/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0310 - acc: 0.9931 - val_loss: 0.0437 - val_acc: 0.9873\n",
            "Epoch 340/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0481 - acc: 0.9904 - val_loss: 0.0253 - val_acc: 0.9963\n",
            "Epoch 341/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0322 - acc: 0.9930 - val_loss: 0.0212 - val_acc: 0.9956\n",
            "Epoch 342/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0321 - acc: 0.9940 - val_loss: 0.0374 - val_acc: 0.9923\n",
            "Epoch 343/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0409 - acc: 0.9918 - val_loss: 0.0465 - val_acc: 0.9934\n",
            "Epoch 344/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0384 - acc: 0.9920 - val_loss: 0.0251 - val_acc: 0.9937\n",
            "Epoch 345/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0361 - acc: 0.9914 - val_loss: 0.0240 - val_acc: 0.9949\n",
            "Epoch 346/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0307 - acc: 0.9921 - val_loss: 0.0348 - val_acc: 0.9925\n",
            "Epoch 347/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0338 - acc: 0.9928 - val_loss: 0.0177 - val_acc: 0.9956\n",
            "Epoch 348/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0334 - acc: 0.9912 - val_loss: 0.0372 - val_acc: 0.9915\n",
            "Epoch 349/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0344 - acc: 0.9910 - val_loss: 0.0484 - val_acc: 0.9902\n",
            "Epoch 350/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0393 - acc: 0.9897 - val_loss: 0.0251 - val_acc: 0.9932\n",
            "Epoch 351/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0382 - acc: 0.9904 - val_loss: 0.0429 - val_acc: 0.9921\n",
            "Epoch 352/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0452 - acc: 0.9889 - val_loss: 0.0453 - val_acc: 0.9877\n",
            "Epoch 353/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0345 - acc: 0.9912 - val_loss: 0.0351 - val_acc: 0.9898\n",
            "Epoch 354/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0401 - acc: 0.9898 - val_loss: 0.0271 - val_acc: 0.9945\n",
            "Epoch 355/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0349 - acc: 0.9918 - val_loss: 0.0224 - val_acc: 0.9948\n",
            "Epoch 356/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0369 - acc: 0.9910 - val_loss: 0.0341 - val_acc: 0.9904\n",
            "Epoch 357/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0355 - acc: 0.9912 - val_loss: 0.0251 - val_acc: 0.9927\n",
            "Epoch 358/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0347 - acc: 0.9909 - val_loss: 0.0348 - val_acc: 0.9932\n",
            "Epoch 359/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0278 - acc: 0.9929 - val_loss: 0.0220 - val_acc: 0.9942\n",
            "Epoch 360/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0370 - acc: 0.9920 - val_loss: 0.0190 - val_acc: 0.9963\n",
            "Epoch 361/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0334 - acc: 0.9917 - val_loss: 0.0364 - val_acc: 0.9910\n",
            "Epoch 362/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0398 - acc: 0.9914 - val_loss: 0.0434 - val_acc: 0.9907\n",
            "Epoch 363/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0316 - acc: 0.9924 - val_loss: 0.0146 - val_acc: 0.9970\n",
            "Epoch 364/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0344 - acc: 0.9917 - val_loss: 0.0284 - val_acc: 0.9931\n",
            "Epoch 365/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0462 - acc: 0.9900 - val_loss: 0.0219 - val_acc: 0.9947\n",
            "Epoch 366/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0341 - acc: 0.9913 - val_loss: 0.0235 - val_acc: 0.9927\n",
            "Epoch 367/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0386 - acc: 0.9903 - val_loss: 0.0198 - val_acc: 0.9945\n",
            "Epoch 368/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0431 - acc: 0.9896 - val_loss: 0.0303 - val_acc: 0.9932\n",
            "Epoch 369/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0335 - acc: 0.9920 - val_loss: 0.0878 - val_acc: 0.9856\n",
            "Epoch 370/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0562 - acc: 0.9896 - val_loss: 0.0544 - val_acc: 0.9856\n",
            "Epoch 371/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0377 - acc: 0.9917 - val_loss: 0.0254 - val_acc: 0.9944\n",
            "Epoch 372/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0303 - acc: 0.9928 - val_loss: 0.0178 - val_acc: 0.9966\n",
            "Epoch 373/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0377 - acc: 0.9919 - val_loss: 0.0285 - val_acc: 0.9934\n",
            "Epoch 374/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0344 - acc: 0.9919 - val_loss: 0.0992 - val_acc: 0.9657\n",
            "Epoch 375/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0387 - acc: 0.9913 - val_loss: 0.0413 - val_acc: 0.9929\n",
            "Epoch 376/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0309 - acc: 0.9925 - val_loss: 0.0207 - val_acc: 0.9956\n",
            "Epoch 377/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0321 - acc: 0.9918 - val_loss: 0.0524 - val_acc: 0.9846\n",
            "Epoch 378/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0308 - acc: 0.9920 - val_loss: 0.0303 - val_acc: 0.9925\n",
            "Epoch 379/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0300 - acc: 0.9927 - val_loss: 0.0569 - val_acc: 0.9896\n",
            "Epoch 380/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0391 - acc: 0.9906 - val_loss: 0.0238 - val_acc: 0.9943\n",
            "Epoch 381/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0317 - acc: 0.9923 - val_loss: 0.0261 - val_acc: 0.9953\n",
            "Epoch 382/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0277 - acc: 0.9932 - val_loss: 0.0183 - val_acc: 0.9954\n",
            "Epoch 383/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0430 - acc: 0.9906 - val_loss: 0.0408 - val_acc: 0.9894\n",
            "Epoch 384/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0340 - acc: 0.9915 - val_loss: 0.0257 - val_acc: 0.9956\n",
            "Epoch 385/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0329 - acc: 0.9916 - val_loss: 0.0185 - val_acc: 0.9958\n",
            "Epoch 386/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0286 - acc: 0.9928 - val_loss: 0.0187 - val_acc: 0.9953\n",
            "Epoch 387/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0321 - acc: 0.9921 - val_loss: 0.0199 - val_acc: 0.9948\n",
            "Epoch 388/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0393 - acc: 0.9908 - val_loss: 0.0662 - val_acc: 0.9874\n",
            "Epoch 389/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0402 - acc: 0.9905 - val_loss: 0.0188 - val_acc: 0.9946\n",
            "Epoch 390/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0276 - acc: 0.9932 - val_loss: 0.0326 - val_acc: 0.9927\n",
            "Epoch 391/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0352 - acc: 0.9926 - val_loss: 0.0268 - val_acc: 0.9937\n",
            "Epoch 392/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0276 - acc: 0.9934 - val_loss: 0.0163 - val_acc: 0.9964\n",
            "Epoch 393/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0315 - acc: 0.9928 - val_loss: 0.0257 - val_acc: 0.9950\n",
            "Epoch 394/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0348 - acc: 0.9923 - val_loss: 0.0829 - val_acc: 0.9859\n",
            "Epoch 395/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0385 - acc: 0.9912 - val_loss: 0.0317 - val_acc: 0.9921\n",
            "Epoch 396/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0399 - acc: 0.9909 - val_loss: 0.0195 - val_acc: 0.9956\n",
            "Epoch 397/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0325 - acc: 0.9920 - val_loss: 0.0242 - val_acc: 0.9949\n",
            "Epoch 398/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0433 - acc: 0.9907 - val_loss: 0.0193 - val_acc: 0.9947\n",
            "Epoch 399/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0437 - acc: 0.9908 - val_loss: 0.0346 - val_acc: 0.9940\n",
            "Epoch 400/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0303 - acc: 0.9928 - val_loss: 0.0226 - val_acc: 0.9945\n",
            "Epoch 401/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0394 - acc: 0.9913 - val_loss: 0.0374 - val_acc: 0.9932\n",
            "Epoch 402/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0376 - acc: 0.9911 - val_loss: 0.0678 - val_acc: 0.9867\n",
            "Epoch 403/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0356 - acc: 0.9915 - val_loss: 0.0726 - val_acc: 0.9861\n",
            "Epoch 404/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0350 - acc: 0.9916 - val_loss: 0.0224 - val_acc: 0.9942\n",
            "Epoch 405/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0333 - acc: 0.9918 - val_loss: 0.0315 - val_acc: 0.9887\n",
            "Epoch 406/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0419 - acc: 0.9900 - val_loss: 0.0360 - val_acc: 0.9917\n",
            "Epoch 407/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0329 - acc: 0.9920 - val_loss: 0.0227 - val_acc: 0.9937\n",
            "Epoch 408/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0377 - acc: 0.9911 - val_loss: 0.0333 - val_acc: 0.9953\n",
            "Epoch 409/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0325 - acc: 0.9921 - val_loss: 0.0368 - val_acc: 0.9916\n",
            "Epoch 410/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0304 - acc: 0.9921 - val_loss: 0.0185 - val_acc: 0.9958\n",
            "Epoch 411/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0256 - acc: 0.9934 - val_loss: 0.0470 - val_acc: 0.9875\n",
            "Epoch 412/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0331 - acc: 0.9921 - val_loss: 0.0169 - val_acc: 0.9959\n",
            "Epoch 413/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0351 - acc: 0.9918 - val_loss: 0.0278 - val_acc: 0.9932\n",
            "Epoch 414/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0290 - acc: 0.9930 - val_loss: 0.0292 - val_acc: 0.9937\n",
            "Epoch 415/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0335 - acc: 0.9921 - val_loss: 0.0165 - val_acc: 0.9966\n",
            "Epoch 416/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0312 - acc: 0.9924 - val_loss: 0.0248 - val_acc: 0.9942\n",
            "Epoch 417/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0309 - acc: 0.9926 - val_loss: 0.0276 - val_acc: 0.9945\n",
            "Epoch 418/1000\n",
            "54924/54924 [==============================] - 2s 30us/step - loss: 0.0335 - acc: 0.9923 - val_loss: 0.0230 - val_acc: 0.9950\n",
            "Epoch 419/1000\n",
            "54924/54924 [==============================] - 2s 30us/step - loss: 0.0330 - acc: 0.9921 - val_loss: 0.0237 - val_acc: 0.9942\n",
            "Epoch 420/1000\n",
            "54924/54924 [==============================] - 2s 30us/step - loss: 0.0329 - acc: 0.9918 - val_loss: 0.0151 - val_acc: 0.9966\n",
            "Epoch 421/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0274 - acc: 0.9935 - val_loss: 0.0449 - val_acc: 0.9910\n",
            "Epoch 422/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0296 - acc: 0.9931 - val_loss: 0.0190 - val_acc: 0.9959\n",
            "Epoch 423/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0366 - acc: 0.9912 - val_loss: 0.0204 - val_acc: 0.9967\n",
            "Epoch 424/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0239 - acc: 0.9939 - val_loss: 0.0133 - val_acc: 0.9969\n",
            "Epoch 425/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0298 - acc: 0.9934 - val_loss: 0.0211 - val_acc: 0.9940\n",
            "Epoch 426/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0288 - acc: 0.9932 - val_loss: 0.0172 - val_acc: 0.9970\n",
            "Epoch 427/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0364 - acc: 0.9920 - val_loss: 0.0209 - val_acc: 0.9948\n",
            "Epoch 428/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0366 - acc: 0.9916 - val_loss: 0.0205 - val_acc: 0.9953\n",
            "Epoch 429/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0322 - acc: 0.9922 - val_loss: 0.0275 - val_acc: 0.9950\n",
            "Epoch 430/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0383 - acc: 0.9927 - val_loss: 0.0303 - val_acc: 0.9930\n",
            "Epoch 431/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0322 - acc: 0.9924 - val_loss: 0.0247 - val_acc: 0.9950\n",
            "Epoch 432/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0306 - acc: 0.9930 - val_loss: 0.0177 - val_acc: 0.9958\n",
            "Epoch 433/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0388 - acc: 0.9919 - val_loss: 0.0196 - val_acc: 0.9956\n",
            "Epoch 434/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0261 - acc: 0.9934 - val_loss: 0.0201 - val_acc: 0.9951\n",
            "Epoch 435/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0272 - acc: 0.9936 - val_loss: 0.0305 - val_acc: 0.9925\n",
            "Epoch 436/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0370 - acc: 0.9916 - val_loss: 0.0415 - val_acc: 0.9902\n",
            "Epoch 437/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0358 - acc: 0.9914 - val_loss: 0.0208 - val_acc: 0.9954\n",
            "Epoch 438/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0246 - acc: 0.9935 - val_loss: 0.0989 - val_acc: 0.9688\n",
            "Epoch 439/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0516 - acc: 0.9901 - val_loss: 0.0446 - val_acc: 0.9908\n",
            "Epoch 440/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0404 - acc: 0.9930 - val_loss: 0.0338 - val_acc: 0.9939\n",
            "Epoch 441/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0430 - acc: 0.9928 - val_loss: 0.0244 - val_acc: 0.9950\n",
            "Epoch 442/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0290 - acc: 0.9943 - val_loss: 0.0359 - val_acc: 0.9943\n",
            "Epoch 443/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0451 - acc: 0.9924 - val_loss: 0.0365 - val_acc: 0.9894\n",
            "Epoch 444/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0360 - acc: 0.9910 - val_loss: 0.0153 - val_acc: 0.9961\n",
            "Epoch 445/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0337 - acc: 0.9926 - val_loss: 0.0180 - val_acc: 0.9947\n",
            "Epoch 446/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0231 - acc: 0.9945 - val_loss: 0.0231 - val_acc: 0.9958\n",
            "Epoch 447/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0441 - acc: 0.9910 - val_loss: 0.0332 - val_acc: 0.9932\n",
            "Epoch 448/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0274 - acc: 0.9938 - val_loss: 0.0351 - val_acc: 0.9921\n",
            "Epoch 449/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0351 - acc: 0.9928 - val_loss: 0.0181 - val_acc: 0.9962\n",
            "Epoch 450/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0292 - acc: 0.9931 - val_loss: 0.0172 - val_acc: 0.9963\n",
            "Epoch 451/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0259 - acc: 0.9939 - val_loss: 0.0423 - val_acc: 0.9915\n",
            "Epoch 452/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0293 - acc: 0.9931 - val_loss: 0.0593 - val_acc: 0.9916\n",
            "Epoch 453/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0334 - acc: 0.9934 - val_loss: 0.0240 - val_acc: 0.9942\n",
            "Epoch 454/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0280 - acc: 0.9929 - val_loss: 0.0142 - val_acc: 0.9976\n",
            "Epoch 455/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0326 - acc: 0.9920 - val_loss: 0.0213 - val_acc: 0.9937\n",
            "Epoch 456/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0259 - acc: 0.9934 - val_loss: 0.0360 - val_acc: 0.9916\n",
            "Epoch 457/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0262 - acc: 0.9937 - val_loss: 0.0149 - val_acc: 0.9974\n",
            "Epoch 458/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0679 - acc: 0.9917 - val_loss: 0.0242 - val_acc: 0.9970\n",
            "Epoch 459/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0349 - acc: 0.9942 - val_loss: 0.0236 - val_acc: 0.9948\n",
            "Epoch 460/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0356 - acc: 0.9930 - val_loss: 0.0231 - val_acc: 0.9950\n",
            "Epoch 461/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0284 - acc: 0.9939 - val_loss: 0.0171 - val_acc: 0.9982\n",
            "Epoch 462/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0271 - acc: 0.9942 - val_loss: 0.0141 - val_acc: 0.9976\n",
            "Epoch 463/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0276 - acc: 0.9947 - val_loss: 0.0388 - val_acc: 0.9908\n",
            "Epoch 464/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0459 - acc: 0.9926 - val_loss: 0.0351 - val_acc: 0.9950\n",
            "Epoch 465/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0290 - acc: 0.9946 - val_loss: 0.0184 - val_acc: 0.9958\n",
            "Epoch 466/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0290 - acc: 0.9947 - val_loss: 0.0359 - val_acc: 0.9929\n",
            "Epoch 467/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0322 - acc: 0.9942 - val_loss: 0.0210 - val_acc: 0.9967\n",
            "Epoch 468/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0328 - acc: 0.9941 - val_loss: 0.0170 - val_acc: 0.9979\n",
            "Epoch 469/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0581 - acc: 0.9904 - val_loss: 0.0517 - val_acc: 0.9908\n",
            "Epoch 470/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0490 - acc: 0.9921 - val_loss: 0.0585 - val_acc: 0.9914\n",
            "Epoch 471/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0495 - acc: 0.9920 - val_loss: 0.0336 - val_acc: 0.9929\n",
            "Epoch 472/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0322 - acc: 0.9943 - val_loss: 0.0513 - val_acc: 0.9910\n",
            "Epoch 473/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0302 - acc: 0.9943 - val_loss: 0.0157 - val_acc: 0.9982\n",
            "Epoch 474/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0283 - acc: 0.9947 - val_loss: 0.0194 - val_acc: 0.9981\n",
            "Epoch 475/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0254 - acc: 0.9954 - val_loss: 0.0174 - val_acc: 0.9980\n",
            "Epoch 476/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0333 - acc: 0.9943 - val_loss: 0.0504 - val_acc: 0.9910\n",
            "Epoch 477/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0315 - acc: 0.9944 - val_loss: 0.0374 - val_acc: 0.9900\n",
            "Epoch 478/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0286 - acc: 0.9947 - val_loss: 0.0207 - val_acc: 0.9958\n",
            "Epoch 479/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0481 - acc: 0.9927 - val_loss: 0.0222 - val_acc: 0.9956\n",
            "Epoch 480/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0383 - acc: 0.9925 - val_loss: 0.0151 - val_acc: 0.9985\n",
            "Epoch 481/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0470 - acc: 0.9912 - val_loss: 0.0369 - val_acc: 0.9924\n",
            "Epoch 482/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0388 - acc: 0.9936 - val_loss: 0.0168 - val_acc: 0.9985\n",
            "Epoch 483/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0437 - acc: 0.9937 - val_loss: 0.0187 - val_acc: 0.9978\n",
            "Epoch 484/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0514 - acc: 0.9902 - val_loss: 0.0230 - val_acc: 0.9945\n",
            "Epoch 485/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0338 - acc: 0.9943 - val_loss: 0.0179 - val_acc: 0.9977\n",
            "Epoch 486/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0359 - acc: 0.9935 - val_loss: 0.0180 - val_acc: 0.9964\n",
            "Epoch 487/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0298 - acc: 0.9946 - val_loss: 0.0138 - val_acc: 0.9989\n",
            "Epoch 488/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0428 - acc: 0.9921 - val_loss: 0.0214 - val_acc: 0.9974\n",
            "Epoch 489/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0313 - acc: 0.9947 - val_loss: 0.0459 - val_acc: 0.9910\n",
            "Epoch 490/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0397 - acc: 0.9930 - val_loss: 0.0267 - val_acc: 0.9941\n",
            "Epoch 491/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0416 - acc: 0.9935 - val_loss: 0.0808 - val_acc: 0.9877\n",
            "Epoch 492/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0272 - acc: 0.9947 - val_loss: 0.0570 - val_acc: 0.9819\n",
            "Epoch 493/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0369 - acc: 0.9939 - val_loss: 0.0360 - val_acc: 0.9930\n",
            "Epoch 494/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0404 - acc: 0.9922 - val_loss: 0.0458 - val_acc: 0.9908\n",
            "Epoch 495/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0404 - acc: 0.9925 - val_loss: 0.0160 - val_acc: 0.9975\n",
            "Epoch 496/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0608 - acc: 0.9916 - val_loss: 0.0119 - val_acc: 0.9990\n",
            "Epoch 497/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0338 - acc: 0.9936 - val_loss: 0.0163 - val_acc: 0.9969\n",
            "Epoch 498/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0272 - acc: 0.9946 - val_loss: 0.0511 - val_acc: 0.9905\n",
            "Epoch 499/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0308 - acc: 0.9939 - val_loss: 0.0449 - val_acc: 0.9912\n",
            "Epoch 500/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0356 - acc: 0.9936 - val_loss: 0.0437 - val_acc: 0.9928\n",
            "Epoch 501/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0438 - acc: 0.9928 - val_loss: 0.0203 - val_acc: 0.9969\n",
            "Epoch 502/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0285 - acc: 0.9954 - val_loss: 0.0183 - val_acc: 0.9966\n",
            "Epoch 503/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0420 - acc: 0.9933 - val_loss: 0.0812 - val_acc: 0.9879\n",
            "Epoch 504/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0320 - acc: 0.9943 - val_loss: 0.0154 - val_acc: 0.9973\n",
            "Epoch 505/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0342 - acc: 0.9934 - val_loss: 0.0388 - val_acc: 0.9922\n",
            "Epoch 506/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0442 - acc: 0.9929 - val_loss: 0.0185 - val_acc: 0.9969\n",
            "Epoch 507/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0265 - acc: 0.9954 - val_loss: 0.0206 - val_acc: 0.9967\n",
            "Epoch 508/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0467 - acc: 0.9924 - val_loss: 0.0189 - val_acc: 0.9963\n",
            "Epoch 509/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0328 - acc: 0.9942 - val_loss: 0.0193 - val_acc: 0.9975\n",
            "Epoch 510/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0378 - acc: 0.9931 - val_loss: 0.0236 - val_acc: 0.9975\n",
            "Epoch 511/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0335 - acc: 0.9937 - val_loss: 0.0147 - val_acc: 0.9985\n",
            "Epoch 512/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0385 - acc: 0.9929 - val_loss: 0.0561 - val_acc: 0.9914\n",
            "Epoch 513/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0422 - acc: 0.9927 - val_loss: 0.0443 - val_acc: 0.9913\n",
            "Epoch 514/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0308 - acc: 0.9934 - val_loss: 0.0182 - val_acc: 0.9969\n",
            "Epoch 515/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0285 - acc: 0.9942 - val_loss: 0.0207 - val_acc: 0.9961\n",
            "Epoch 516/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0393 - acc: 0.9932 - val_loss: 0.0176 - val_acc: 0.9974\n",
            "Epoch 517/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0281 - acc: 0.9942 - val_loss: 0.0147 - val_acc: 0.9980\n",
            "Epoch 518/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0456 - acc: 0.9911 - val_loss: 0.0862 - val_acc: 0.9726\n",
            "Epoch 519/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0272 - acc: 0.9937 - val_loss: 0.0898 - val_acc: 0.9875\n",
            "Epoch 520/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0395 - acc: 0.9927 - val_loss: 0.0284 - val_acc: 0.9967\n",
            "Epoch 521/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0500 - acc: 0.9912 - val_loss: 0.0158 - val_acc: 0.9985\n",
            "Epoch 522/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0323 - acc: 0.9941 - val_loss: 0.0129 - val_acc: 0.9988\n",
            "Epoch 523/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0252 - acc: 0.9948 - val_loss: 0.0276 - val_acc: 0.9938\n",
            "Epoch 524/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0360 - acc: 0.9939 - val_loss: 0.0177 - val_acc: 0.9989\n",
            "Epoch 525/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0322 - acc: 0.9933 - val_loss: 0.0159 - val_acc: 0.9979\n",
            "Epoch 526/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0384 - acc: 0.9922 - val_loss: 0.0162 - val_acc: 0.9977\n",
            "Epoch 527/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0351 - acc: 0.9924 - val_loss: 0.0172 - val_acc: 0.9965\n",
            "Epoch 528/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0319 - acc: 0.9935 - val_loss: 0.0312 - val_acc: 0.9926\n",
            "Epoch 529/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0356 - acc: 0.9936 - val_loss: 0.0184 - val_acc: 0.9980\n",
            "Epoch 530/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0200 - acc: 0.9957 - val_loss: 0.0541 - val_acc: 0.9896\n",
            "Epoch 531/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0309 - acc: 0.9942 - val_loss: 0.0412 - val_acc: 0.9926\n",
            "Epoch 532/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0392 - acc: 0.9924 - val_loss: 0.0232 - val_acc: 0.9951\n",
            "Epoch 533/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0312 - acc: 0.9942 - val_loss: 0.1886 - val_acc: 0.9806\n",
            "Epoch 534/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0361 - acc: 0.9928 - val_loss: 0.0111 - val_acc: 0.9983\n",
            "Epoch 535/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0248 - acc: 0.9946 - val_loss: 0.0128 - val_acc: 0.9988\n",
            "Epoch 536/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0400 - acc: 0.9917 - val_loss: 0.0186 - val_acc: 0.9990\n",
            "Epoch 537/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0288 - acc: 0.9939 - val_loss: 0.0384 - val_acc: 0.9933\n",
            "Epoch 538/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0334 - acc: 0.9941 - val_loss: 0.1144 - val_acc: 0.9645\n",
            "Epoch 539/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0242 - acc: 0.9939 - val_loss: 0.0949 - val_acc: 0.9622\n",
            "Epoch 540/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0260 - acc: 0.9943 - val_loss: 0.0159 - val_acc: 0.9980\n",
            "Epoch 541/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0279 - acc: 0.9945 - val_loss: 0.0243 - val_acc: 0.9903\n",
            "Epoch 542/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0257 - acc: 0.9949 - val_loss: 0.0206 - val_acc: 0.9979\n",
            "Epoch 543/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0440 - acc: 0.9918 - val_loss: 0.0142 - val_acc: 0.9972\n",
            "Epoch 544/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0281 - acc: 0.9937 - val_loss: 0.0111 - val_acc: 0.9988\n",
            "Epoch 545/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0291 - acc: 0.9939 - val_loss: 0.0314 - val_acc: 0.9929\n",
            "Epoch 546/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0285 - acc: 0.9945 - val_loss: 0.0155 - val_acc: 0.9985\n",
            "Epoch 547/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0376 - acc: 0.9927 - val_loss: 0.0116 - val_acc: 0.9982\n",
            "Epoch 548/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0329 - acc: 0.9929 - val_loss: 0.0193 - val_acc: 0.9982\n",
            "Epoch 549/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0204 - acc: 0.9956 - val_loss: 0.0378 - val_acc: 0.9917\n",
            "Epoch 550/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0268 - acc: 0.9948 - val_loss: 0.0217 - val_acc: 0.9949\n",
            "Epoch 551/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0305 - acc: 0.9948 - val_loss: 0.0128 - val_acc: 0.9986\n",
            "Epoch 552/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0358 - acc: 0.9923 - val_loss: 0.1062 - val_acc: 0.9891\n",
            "Epoch 553/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0297 - acc: 0.9943 - val_loss: 0.0189 - val_acc: 0.9964\n",
            "Epoch 554/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0232 - acc: 0.9950 - val_loss: 0.1575 - val_acc: 0.9640\n",
            "Epoch 555/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0563 - acc: 0.9912 - val_loss: 0.0158 - val_acc: 0.9965\n",
            "Epoch 556/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0405 - acc: 0.9924 - val_loss: 0.0178 - val_acc: 0.9971\n",
            "Epoch 557/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0326 - acc: 0.9931 - val_loss: 0.0236 - val_acc: 0.9943\n",
            "Epoch 558/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0376 - acc: 0.9935 - val_loss: 0.0159 - val_acc: 0.9978\n",
            "Epoch 559/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0209 - acc: 0.9961 - val_loss: 0.0131 - val_acc: 0.9981\n",
            "Epoch 560/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0315 - acc: 0.9936 - val_loss: 0.0137 - val_acc: 0.9980\n",
            "Epoch 561/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0377 - acc: 0.9921 - val_loss: 0.0266 - val_acc: 0.9949\n",
            "Epoch 562/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0338 - acc: 0.9937 - val_loss: 0.0180 - val_acc: 0.9965\n",
            "Epoch 563/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0283 - acc: 0.9940 - val_loss: 0.0215 - val_acc: 0.9948\n",
            "Epoch 564/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0356 - acc: 0.9926 - val_loss: 0.0335 - val_acc: 0.9927\n",
            "Epoch 565/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0344 - acc: 0.9937 - val_loss: 0.0160 - val_acc: 0.9977\n",
            "Epoch 566/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0416 - acc: 0.9935 - val_loss: 0.0133 - val_acc: 0.9982\n",
            "Epoch 567/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0300 - acc: 0.9938 - val_loss: 0.0179 - val_acc: 0.9983\n",
            "Epoch 568/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0258 - acc: 0.9944 - val_loss: 0.0176 - val_acc: 0.9956\n",
            "Epoch 569/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0237 - acc: 0.9951 - val_loss: 0.0124 - val_acc: 0.9983\n",
            "Epoch 570/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0280 - acc: 0.9944 - val_loss: 0.0366 - val_acc: 0.9923\n",
            "Epoch 571/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0487 - acc: 0.9924 - val_loss: 0.1520 - val_acc: 0.9851\n",
            "Epoch 572/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0375 - acc: 0.9930 - val_loss: 0.0443 - val_acc: 0.9912\n",
            "Epoch 573/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0355 - acc: 0.9929 - val_loss: 0.0109 - val_acc: 0.9980\n",
            "Epoch 574/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0382 - acc: 0.9921 - val_loss: 0.0240 - val_acc: 0.9942\n",
            "Epoch 575/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0233 - acc: 0.9955 - val_loss: 0.0198 - val_acc: 0.9964\n",
            "Epoch 576/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0298 - acc: 0.9942 - val_loss: 0.0587 - val_acc: 0.9894\n",
            "Epoch 577/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0315 - acc: 0.9936 - val_loss: 0.1055 - val_acc: 0.9867\n",
            "Epoch 578/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0252 - acc: 0.9950 - val_loss: 0.0143 - val_acc: 0.9976\n",
            "Epoch 579/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0276 - acc: 0.9947 - val_loss: 0.0222 - val_acc: 0.9952\n",
            "Epoch 580/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0370 - acc: 0.9931 - val_loss: 0.0304 - val_acc: 0.9942\n",
            "Epoch 581/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0377 - acc: 0.9927 - val_loss: 0.0136 - val_acc: 0.9975\n",
            "Epoch 582/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0280 - acc: 0.9945 - val_loss: 0.0167 - val_acc: 0.9970\n",
            "Epoch 583/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0233 - acc: 0.9953 - val_loss: 0.0235 - val_acc: 0.9932\n",
            "Epoch 584/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0397 - acc: 0.9922 - val_loss: 0.0149 - val_acc: 0.9982\n",
            "Epoch 585/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0243 - acc: 0.9950 - val_loss: 0.0126 - val_acc: 0.9975\n",
            "Epoch 586/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0531 - acc: 0.9910 - val_loss: 0.0198 - val_acc: 0.9954\n",
            "Epoch 587/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0327 - acc: 0.9936 - val_loss: 0.0329 - val_acc: 0.9902\n",
            "Epoch 588/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0324 - acc: 0.9935 - val_loss: 0.0276 - val_acc: 0.9935\n",
            "Epoch 589/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0312 - acc: 0.9938 - val_loss: 0.0124 - val_acc: 0.9991\n",
            "Epoch 590/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0286 - acc: 0.9942 - val_loss: 0.0168 - val_acc: 0.9963\n",
            "Epoch 591/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0272 - acc: 0.9934 - val_loss: 0.0369 - val_acc: 0.9867\n",
            "Epoch 592/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0234 - acc: 0.9951 - val_loss: 0.0260 - val_acc: 0.9969\n",
            "Epoch 593/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0241 - acc: 0.9949 - val_loss: 0.0169 - val_acc: 0.9976\n",
            "Epoch 594/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0209 - acc: 0.9955 - val_loss: 0.0252 - val_acc: 0.9936\n",
            "Epoch 595/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0345 - acc: 0.9938 - val_loss: 0.0500 - val_acc: 0.9851\n",
            "Epoch 596/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0232 - acc: 0.9952 - val_loss: 0.0112 - val_acc: 0.9987\n",
            "Epoch 597/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0327 - acc: 0.9929 - val_loss: 0.0738 - val_acc: 0.9873\n",
            "Epoch 598/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0431 - acc: 0.9902 - val_loss: 0.0249 - val_acc: 0.9975\n",
            "Epoch 599/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0236 - acc: 0.9952 - val_loss: 0.0191 - val_acc: 0.9953\n",
            "Epoch 600/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0264 - acc: 0.9950 - val_loss: 0.0150 - val_acc: 0.9983\n",
            "Epoch 601/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0352 - acc: 0.9925 - val_loss: 0.0132 - val_acc: 0.9981\n",
            "Epoch 602/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0351 - acc: 0.9932 - val_loss: 0.0122 - val_acc: 0.9983\n",
            "Epoch 603/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0203 - acc: 0.9954 - val_loss: 0.0439 - val_acc: 0.9881\n",
            "Epoch 604/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0283 - acc: 0.9944 - val_loss: 0.0148 - val_acc: 0.9978\n",
            "Epoch 605/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0236 - acc: 0.9956 - val_loss: 0.0345 - val_acc: 0.9839\n",
            "Epoch 606/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0265 - acc: 0.9945 - val_loss: 0.0228 - val_acc: 0.9947\n",
            "Epoch 607/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0264 - acc: 0.9943 - val_loss: 0.0094 - val_acc: 0.9979\n",
            "Epoch 608/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0270 - acc: 0.9942 - val_loss: 0.0145 - val_acc: 0.9977\n",
            "Epoch 609/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0250 - acc: 0.9940 - val_loss: 0.0176 - val_acc: 0.9959\n",
            "Epoch 610/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0213 - acc: 0.9954 - val_loss: 0.0162 - val_acc: 0.9971\n",
            "Epoch 611/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0209 - acc: 0.9954 - val_loss: 0.0174 - val_acc: 0.9959\n",
            "Epoch 612/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0400 - acc: 0.9922 - val_loss: 0.0156 - val_acc: 0.9983\n",
            "Epoch 613/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0247 - acc: 0.9949 - val_loss: 0.0169 - val_acc: 0.9980\n",
            "Epoch 614/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0268 - acc: 0.9949 - val_loss: 0.0359 - val_acc: 0.9913\n",
            "Epoch 615/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0380 - acc: 0.9928 - val_loss: 0.0153 - val_acc: 0.9972\n",
            "Epoch 616/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0404 - acc: 0.9938 - val_loss: 0.0114 - val_acc: 0.9986\n",
            "Epoch 617/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0528 - acc: 0.9924 - val_loss: 0.0114 - val_acc: 0.9988\n",
            "Epoch 618/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0455 - acc: 0.9929 - val_loss: 0.0147 - val_acc: 0.9983\n",
            "Epoch 619/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0417 - acc: 0.9942 - val_loss: 0.0300 - val_acc: 0.9949\n",
            "Epoch 620/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0495 - acc: 0.9922 - val_loss: 0.0717 - val_acc: 0.9908\n",
            "Epoch 621/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.1004 - acc: 0.9885 - val_loss: 0.0747 - val_acc: 0.9909\n",
            "Epoch 622/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0834 - acc: 0.9902 - val_loss: 0.0393 - val_acc: 0.9942\n",
            "Epoch 623/1000\n",
            "54924/54924 [==============================] - 2s 30us/step - loss: 0.0691 - acc: 0.9910 - val_loss: 0.0223 - val_acc: 0.9969\n",
            "Epoch 624/1000\n",
            "54924/54924 [==============================] - 2s 30us/step - loss: 0.0374 - acc: 0.9944 - val_loss: 0.0246 - val_acc: 0.9957\n",
            "Epoch 625/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0714 - acc: 0.9912 - val_loss: 0.0326 - val_acc: 0.9959\n",
            "Epoch 626/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0500 - acc: 0.9918 - val_loss: 0.0217 - val_acc: 0.9967\n",
            "Epoch 627/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0413 - acc: 0.9939 - val_loss: 0.0176 - val_acc: 0.9985\n",
            "Epoch 628/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0420 - acc: 0.9935 - val_loss: 0.0101 - val_acc: 0.9991\n",
            "Epoch 629/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0765 - acc: 0.9890 - val_loss: 0.0187 - val_acc: 0.9974\n",
            "Epoch 630/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0273 - acc: 0.9952 - val_loss: 0.0670 - val_acc: 0.9905\n",
            "Epoch 631/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0259 - acc: 0.9956 - val_loss: 0.0959 - val_acc: 0.9846\n",
            "Epoch 632/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0418 - acc: 0.9936 - val_loss: 0.1857 - val_acc: 0.9641\n",
            "Epoch 633/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0320 - acc: 0.9938 - val_loss: 0.0109 - val_acc: 0.9985\n",
            "Epoch 634/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0232 - acc: 0.9946 - val_loss: 0.0177 - val_acc: 0.9968\n",
            "Epoch 635/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0323 - acc: 0.9935 - val_loss: 0.0366 - val_acc: 0.9921\n",
            "Epoch 636/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0270 - acc: 0.9948 - val_loss: 0.0196 - val_acc: 0.9961\n",
            "Epoch 637/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0248 - acc: 0.9950 - val_loss: 0.0115 - val_acc: 0.9983\n",
            "Epoch 638/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0709 - acc: 0.9904 - val_loss: 0.0159 - val_acc: 0.9972\n",
            "Epoch 639/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0510 - acc: 0.9914 - val_loss: 0.8351 - val_acc: 0.8239\n",
            "Epoch 640/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0332 - acc: 0.9939 - val_loss: 0.0161 - val_acc: 0.9969\n",
            "Epoch 641/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0244 - acc: 0.9953 - val_loss: 0.0135 - val_acc: 0.9974\n",
            "Epoch 642/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0254 - acc: 0.9940 - val_loss: 0.0493 - val_acc: 0.9908\n",
            "Epoch 643/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0237 - acc: 0.9946 - val_loss: 0.0159 - val_acc: 0.9970\n",
            "Epoch 644/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0369 - acc: 0.9942 - val_loss: 0.0133 - val_acc: 0.9980\n",
            "Epoch 645/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0242 - acc: 0.9950 - val_loss: 0.0170 - val_acc: 0.9972\n",
            "Epoch 646/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0223 - acc: 0.9946 - val_loss: 0.0188 - val_acc: 0.9971\n",
            "Epoch 647/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0276 - acc: 0.9943 - val_loss: 0.0141 - val_acc: 0.9985\n",
            "Epoch 648/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0262 - acc: 0.9946 - val_loss: 0.0385 - val_acc: 0.9889\n",
            "Epoch 649/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0366 - acc: 0.9939 - val_loss: 0.0481 - val_acc: 0.9917\n",
            "Epoch 650/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0347 - acc: 0.9937 - val_loss: 0.0140 - val_acc: 0.9982\n",
            "Epoch 651/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0317 - acc: 0.9942 - val_loss: 0.0202 - val_acc: 0.9981\n",
            "Epoch 652/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0252 - acc: 0.9944 - val_loss: 0.0147 - val_acc: 0.9975\n",
            "Epoch 653/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0442 - acc: 0.9938 - val_loss: 0.1168 - val_acc: 0.9886\n",
            "Epoch 654/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0266 - acc: 0.9955 - val_loss: 0.0143 - val_acc: 0.9963\n",
            "Epoch 655/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0233 - acc: 0.9951 - val_loss: 0.0245 - val_acc: 0.9966\n",
            "Epoch 656/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0199 - acc: 0.9959 - val_loss: 0.0113 - val_acc: 0.9983\n",
            "Epoch 657/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0246 - acc: 0.9949 - val_loss: 0.0167 - val_acc: 0.9963\n",
            "Epoch 658/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0306 - acc: 0.9936 - val_loss: 0.0322 - val_acc: 0.9881\n",
            "Epoch 659/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0218 - acc: 0.9953 - val_loss: 0.0082 - val_acc: 0.9983\n",
            "Epoch 660/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0244 - acc: 0.9945 - val_loss: 0.0119 - val_acc: 0.9981\n",
            "Epoch 661/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0423 - acc: 0.9923 - val_loss: 0.0190 - val_acc: 0.9978\n",
            "Epoch 662/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0329 - acc: 0.9932 - val_loss: 0.0199 - val_acc: 0.9951\n",
            "Epoch 663/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0228 - acc: 0.9950 - val_loss: 0.0301 - val_acc: 0.9932\n",
            "Epoch 664/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0196 - acc: 0.9954 - val_loss: 0.0144 - val_acc: 0.9979\n",
            "Epoch 665/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0374 - acc: 0.9928 - val_loss: 0.0143 - val_acc: 0.9982\n",
            "Epoch 666/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0289 - acc: 0.9942 - val_loss: 0.0133 - val_acc: 0.9977\n",
            "Epoch 667/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0272 - acc: 0.9946 - val_loss: 0.0312 - val_acc: 0.9924\n",
            "Epoch 668/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0242 - acc: 0.9951 - val_loss: 0.0131 - val_acc: 0.9977\n",
            "Epoch 669/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0553 - acc: 0.9906 - val_loss: 0.0259 - val_acc: 0.9958\n",
            "Epoch 670/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0177 - acc: 0.9959 - val_loss: 0.0564 - val_acc: 0.9797\n",
            "Epoch 671/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0254 - acc: 0.9944 - val_loss: 0.0102 - val_acc: 0.9988\n",
            "Epoch 672/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0237 - acc: 0.9950 - val_loss: 0.0119 - val_acc: 0.9983\n",
            "Epoch 673/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0238 - acc: 0.9950 - val_loss: 0.0226 - val_acc: 0.9945\n",
            "Epoch 674/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0415 - acc: 0.9916 - val_loss: 0.0144 - val_acc: 0.9980\n",
            "Epoch 675/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0183 - acc: 0.9965 - val_loss: 0.0125 - val_acc: 0.9978\n",
            "Epoch 676/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0350 - acc: 0.9942 - val_loss: 0.0183 - val_acc: 0.9980\n",
            "Epoch 677/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0178 - acc: 0.9962 - val_loss: 0.0372 - val_acc: 0.9926\n",
            "Epoch 678/1000\n",
            "54924/54924 [==============================] - 2s 30us/step - loss: 0.0308 - acc: 0.9944 - val_loss: 0.0180 - val_acc: 0.9976\n",
            "Epoch 679/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0360 - acc: 0.9930 - val_loss: 0.0159 - val_acc: 0.9972\n",
            "Epoch 680/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0258 - acc: 0.9957 - val_loss: 0.0123 - val_acc: 0.9967\n",
            "Epoch 681/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0223 - acc: 0.9942 - val_loss: 0.0498 - val_acc: 0.9908\n",
            "Epoch 682/1000\n",
            "54924/54924 [==============================] - 2s 30us/step - loss: 0.0259 - acc: 0.9936 - val_loss: 0.0138 - val_acc: 0.9974\n",
            "Epoch 683/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0218 - acc: 0.9951 - val_loss: 0.0141 - val_acc: 0.9972\n",
            "Epoch 684/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0246 - acc: 0.9956 - val_loss: 0.1630 - val_acc: 0.9836\n",
            "Epoch 685/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0227 - acc: 0.9960 - val_loss: 0.0144 - val_acc: 0.9985\n",
            "Epoch 686/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0277 - acc: 0.9940 - val_loss: 0.0110 - val_acc: 0.9983\n",
            "Epoch 687/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0262 - acc: 0.9949 - val_loss: 0.0421 - val_acc: 0.9911\n",
            "Epoch 688/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0256 - acc: 0.9946 - val_loss: 0.0119 - val_acc: 0.9983\n",
            "Epoch 689/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0239 - acc: 0.9953 - val_loss: 0.0260 - val_acc: 0.9963\n",
            "Epoch 690/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0257 - acc: 0.9948 - val_loss: 0.0202 - val_acc: 0.9957\n",
            "Epoch 691/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0267 - acc: 0.9950 - val_loss: 0.0803 - val_acc: 0.9883\n",
            "Epoch 692/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0345 - acc: 0.9936 - val_loss: 0.0124 - val_acc: 0.9985\n",
            "Epoch 693/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0281 - acc: 0.9943 - val_loss: 0.0136 - val_acc: 0.9983\n",
            "Epoch 694/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0223 - acc: 0.9952 - val_loss: 0.0496 - val_acc: 0.9816\n",
            "Epoch 695/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0271 - acc: 0.9948 - val_loss: 0.0165 - val_acc: 0.9971\n",
            "Epoch 696/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0270 - acc: 0.9950 - val_loss: 0.0103 - val_acc: 0.9993\n",
            "Epoch 697/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0155 - acc: 0.9968 - val_loss: 0.0430 - val_acc: 0.9918\n",
            "Epoch 698/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0246 - acc: 0.9951 - val_loss: 0.0114 - val_acc: 0.9985\n",
            "Epoch 699/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0228 - acc: 0.9949 - val_loss: 0.0182 - val_acc: 0.9961\n",
            "Epoch 700/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0269 - acc: 0.9945 - val_loss: 0.0187 - val_acc: 0.9952\n",
            "Epoch 701/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0334 - acc: 0.9929 - val_loss: 0.0198 - val_acc: 0.9956\n",
            "Epoch 702/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0430 - acc: 0.9928 - val_loss: 0.0185 - val_acc: 0.9951\n",
            "Epoch 703/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0289 - acc: 0.9940 - val_loss: 0.0347 - val_acc: 0.9921\n",
            "Epoch 704/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0211 - acc: 0.9951 - val_loss: 0.0136 - val_acc: 0.9974\n",
            "Epoch 705/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0194 - acc: 0.9953 - val_loss: 0.0136 - val_acc: 0.9975\n",
            "Epoch 706/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0313 - acc: 0.9936 - val_loss: 0.0337 - val_acc: 0.9897\n",
            "Epoch 707/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0230 - acc: 0.9949 - val_loss: 0.0121 - val_acc: 0.9979\n",
            "Epoch 708/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0224 - acc: 0.9950 - val_loss: 0.0175 - val_acc: 0.9960\n",
            "Epoch 709/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0217 - acc: 0.9957 - val_loss: 0.0208 - val_acc: 0.9952\n",
            "Epoch 710/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0427 - acc: 0.9937 - val_loss: 0.0136 - val_acc: 0.9980\n",
            "Epoch 711/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0412 - acc: 0.9945 - val_loss: 0.0199 - val_acc: 0.9970\n",
            "Epoch 712/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0319 - acc: 0.9952 - val_loss: 0.0589 - val_acc: 0.9922\n",
            "Epoch 713/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0640 - acc: 0.9930 - val_loss: 0.0509 - val_acc: 0.9934\n",
            "Epoch 714/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1007 - acc: 0.9895 - val_loss: 0.0110 - val_acc: 0.9983\n",
            "Epoch 715/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0971 - acc: 0.9890 - val_loss: 0.0179 - val_acc: 0.9971\n",
            "Epoch 716/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0490 - acc: 0.9931 - val_loss: 0.0084 - val_acc: 0.9989\n",
            "Epoch 717/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0385 - acc: 0.9943 - val_loss: 0.0097 - val_acc: 0.9989\n",
            "Epoch 718/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0433 - acc: 0.9940 - val_loss: 0.0550 - val_acc: 0.9924\n",
            "Epoch 719/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0421 - acc: 0.9938 - val_loss: 0.0125 - val_acc: 0.9984\n",
            "Epoch 720/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0325 - acc: 0.9949 - val_loss: 0.0110 - val_acc: 0.9983\n",
            "Epoch 721/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0558 - acc: 0.9924 - val_loss: 0.0150 - val_acc: 0.9980\n",
            "Epoch 722/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0359 - acc: 0.9948 - val_loss: 0.0178 - val_acc: 0.9976\n",
            "Epoch 723/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0408 - acc: 0.9948 - val_loss: 0.0131 - val_acc: 0.9983\n",
            "Epoch 724/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0311 - acc: 0.9951 - val_loss: 0.0095 - val_acc: 0.9990\n",
            "Epoch 725/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0259 - acc: 0.9962 - val_loss: 0.0080 - val_acc: 0.9991\n",
            "Epoch 726/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0669 - acc: 0.9909 - val_loss: 0.0145 - val_acc: 0.9973\n",
            "Epoch 727/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0210 - acc: 0.9960 - val_loss: 0.0194 - val_acc: 0.9975\n",
            "Epoch 728/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0576 - acc: 0.9933 - val_loss: 0.1021 - val_acc: 0.9889\n",
            "Epoch 729/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0308 - acc: 0.9952 - val_loss: 0.0094 - val_acc: 0.9989\n",
            "Epoch 730/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0350 - acc: 0.9951 - val_loss: 0.1090 - val_acc: 0.9877\n",
            "Epoch 731/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0586 - acc: 0.9925 - val_loss: 0.0528 - val_acc: 0.9918\n",
            "Epoch 732/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0283 - acc: 0.9963 - val_loss: 0.0094 - val_acc: 0.9991\n",
            "Epoch 733/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0501 - acc: 0.9934 - val_loss: 0.0181 - val_acc: 0.9981\n",
            "Epoch 734/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0299 - acc: 0.9954 - val_loss: 0.0147 - val_acc: 0.9977\n",
            "Epoch 735/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0816 - acc: 0.9895 - val_loss: 0.2378 - val_acc: 0.9780\n",
            "Epoch 736/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0360 - acc: 0.9953 - val_loss: 0.0128 - val_acc: 0.9984\n",
            "Epoch 737/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0365 - acc: 0.9947 - val_loss: 0.0130 - val_acc: 0.9985\n",
            "Epoch 738/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0424 - acc: 0.9938 - val_loss: 0.0160 - val_acc: 0.9979\n",
            "Epoch 739/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0488 - acc: 0.9926 - val_loss: 0.0127 - val_acc: 0.9985\n",
            "Epoch 740/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0506 - acc: 0.9928 - val_loss: 0.0133 - val_acc: 0.9985\n",
            "Epoch 741/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0347 - acc: 0.9943 - val_loss: 0.0313 - val_acc: 0.9937\n",
            "Epoch 742/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0181 - acc: 0.9958 - val_loss: 0.0093 - val_acc: 0.9988\n",
            "Epoch 743/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0460 - acc: 0.9938 - val_loss: 0.0252 - val_acc: 0.9917\n",
            "Epoch 744/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0187 - acc: 0.9957 - val_loss: 0.0214 - val_acc: 0.9944\n",
            "Epoch 745/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0224 - acc: 0.9949 - val_loss: 0.0095 - val_acc: 0.9988\n",
            "Epoch 746/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0259 - acc: 0.9946 - val_loss: 0.0127 - val_acc: 0.9994\n",
            "Epoch 747/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0274 - acc: 0.9940 - val_loss: 0.0993 - val_acc: 0.9870\n",
            "Epoch 748/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0267 - acc: 0.9938 - val_loss: 0.0232 - val_acc: 0.9929\n",
            "Epoch 749/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0192 - acc: 0.9957 - val_loss: 0.0160 - val_acc: 0.9980\n",
            "Epoch 750/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0260 - acc: 0.9948 - val_loss: 0.1321 - val_acc: 0.9862\n",
            "Epoch 751/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0436 - acc: 0.9931 - val_loss: 0.0448 - val_acc: 0.9906\n",
            "Epoch 752/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0265 - acc: 0.9940 - val_loss: 0.0112 - val_acc: 0.9988\n",
            "Epoch 753/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0218 - acc: 0.9946 - val_loss: 0.0116 - val_acc: 0.9991\n",
            "Epoch 754/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0457 - acc: 0.9942 - val_loss: 0.0429 - val_acc: 0.9827\n",
            "Epoch 755/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0518 - acc: 0.9928 - val_loss: 0.1487 - val_acc: 0.9855\n",
            "Epoch 756/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0438 - acc: 0.9941 - val_loss: 0.0164 - val_acc: 0.9977\n",
            "Epoch 757/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0422 - acc: 0.9940 - val_loss: 0.0096 - val_acc: 0.9988\n",
            "Epoch 758/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0540 - acc: 0.9931 - val_loss: 0.0248 - val_acc: 0.9967\n",
            "Epoch 759/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0374 - acc: 0.9949 - val_loss: 0.0100 - val_acc: 0.9989\n",
            "Epoch 760/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0345 - acc: 0.9953 - val_loss: 0.0137 - val_acc: 0.9987\n",
            "Epoch 761/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0488 - acc: 0.9928 - val_loss: 0.0239 - val_acc: 0.9961\n",
            "Epoch 762/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0391 - acc: 0.9946 - val_loss: 0.0115 - val_acc: 0.9986\n",
            "Epoch 763/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0564 - acc: 0.9928 - val_loss: 0.0123 - val_acc: 0.9986\n",
            "Epoch 764/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0212 - acc: 0.9959 - val_loss: 0.0286 - val_acc: 0.9956\n",
            "Epoch 765/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0408 - acc: 0.9940 - val_loss: 0.0215 - val_acc: 0.9964\n",
            "Epoch 766/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0550 - acc: 0.9913 - val_loss: 0.0122 - val_acc: 0.9980\n",
            "Epoch 767/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0326 - acc: 0.9943 - val_loss: 0.0099 - val_acc: 0.9992\n",
            "Epoch 768/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0181 - acc: 0.9961 - val_loss: 0.0072 - val_acc: 0.9992\n",
            "Epoch 769/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0227 - acc: 0.9947 - val_loss: 0.0149 - val_acc: 0.9985\n",
            "Epoch 770/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0250 - acc: 0.9949 - val_loss: 0.0116 - val_acc: 0.9993\n",
            "Epoch 771/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0295 - acc: 0.9938 - val_loss: 0.0088 - val_acc: 0.9992\n",
            "Epoch 772/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0241 - acc: 0.9954 - val_loss: 0.0132 - val_acc: 0.9988\n",
            "Epoch 773/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0222 - acc: 0.9946 - val_loss: 0.0124 - val_acc: 0.9987\n",
            "Epoch 774/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0206 - acc: 0.9956 - val_loss: 0.0132 - val_acc: 0.9980\n",
            "Epoch 775/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0205 - acc: 0.9949 - val_loss: 0.0336 - val_acc: 0.9921\n",
            "Epoch 776/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0233 - acc: 0.9955 - val_loss: 0.0134 - val_acc: 0.9978\n",
            "Epoch 777/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0260 - acc: 0.9943 - val_loss: 0.0242 - val_acc: 0.9969\n",
            "Epoch 778/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0208 - acc: 0.9958 - val_loss: 0.0161 - val_acc: 0.9961\n",
            "Epoch 779/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0712 - acc: 0.9920 - val_loss: 0.0491 - val_acc: 0.9928\n",
            "Epoch 780/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0259 - acc: 0.9957 - val_loss: 0.0270 - val_acc: 0.9941\n",
            "Epoch 781/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0230 - acc: 0.9945 - val_loss: 0.0245 - val_acc: 0.9934\n",
            "Epoch 782/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0232 - acc: 0.9952 - val_loss: 0.0141 - val_acc: 0.9969\n",
            "Epoch 783/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0230 - acc: 0.9948 - val_loss: 0.0123 - val_acc: 0.9984\n",
            "Epoch 784/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0212 - acc: 0.9958 - val_loss: 0.0583 - val_acc: 0.9716\n",
            "Epoch 785/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0168 - acc: 0.9960 - val_loss: 0.0229 - val_acc: 0.9943\n",
            "Epoch 786/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0269 - acc: 0.9944 - val_loss: 0.0122 - val_acc: 0.9983\n",
            "Epoch 787/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0227 - acc: 0.9948 - val_loss: 0.0287 - val_acc: 0.9934\n",
            "Epoch 788/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0171 - acc: 0.9959 - val_loss: 0.0181 - val_acc: 0.9954\n",
            "Epoch 789/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0224 - acc: 0.9947 - val_loss: 0.0204 - val_acc: 0.9980\n",
            "Epoch 790/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0223 - acc: 0.9958 - val_loss: 0.0229 - val_acc: 0.9967\n",
            "Epoch 791/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0237 - acc: 0.9950 - val_loss: 0.0098 - val_acc: 0.9987\n",
            "Epoch 792/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0269 - acc: 0.9955 - val_loss: 0.0174 - val_acc: 0.9963\n",
            "Epoch 793/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0270 - acc: 0.9942 - val_loss: 0.0138 - val_acc: 0.9979\n",
            "Epoch 794/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0282 - acc: 0.9944 - val_loss: 0.0232 - val_acc: 0.9934\n",
            "Epoch 795/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0252 - acc: 0.9953 - val_loss: 0.0113 - val_acc: 0.9988\n",
            "Epoch 796/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0291 - acc: 0.9943 - val_loss: 0.0363 - val_acc: 0.9912\n",
            "Epoch 797/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0207 - acc: 0.9956 - val_loss: 0.0800 - val_acc: 0.9752\n",
            "Epoch 798/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0277 - acc: 0.9941 - val_loss: 0.0108 - val_acc: 0.9983\n",
            "Epoch 799/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0177 - acc: 0.9960 - val_loss: 0.0585 - val_acc: 0.9909\n",
            "Epoch 800/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0242 - acc: 0.9946 - val_loss: 0.0375 - val_acc: 0.9907\n",
            "Epoch 801/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0207 - acc: 0.9956 - val_loss: 0.0191 - val_acc: 0.9950\n",
            "Epoch 802/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0254 - acc: 0.9945 - val_loss: 0.0284 - val_acc: 0.9942\n",
            "Epoch 803/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0251 - acc: 0.9944 - val_loss: 0.0175 - val_acc: 0.9953\n",
            "Epoch 804/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0207 - acc: 0.9956 - val_loss: 0.0451 - val_acc: 0.9922\n",
            "Epoch 805/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0222 - acc: 0.9949 - val_loss: 0.0099 - val_acc: 0.9985\n",
            "Epoch 806/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0218 - acc: 0.9949 - val_loss: 0.0244 - val_acc: 0.9930\n",
            "Epoch 807/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0231 - acc: 0.9945 - val_loss: 0.0107 - val_acc: 0.9980\n",
            "Epoch 808/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0187 - acc: 0.9954 - val_loss: 0.0278 - val_acc: 0.9931\n",
            "Epoch 809/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0170 - acc: 0.9964 - val_loss: 0.0082 - val_acc: 0.9991\n",
            "Epoch 810/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0198 - acc: 0.9953 - val_loss: 0.0118 - val_acc: 0.9980\n",
            "Epoch 811/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0180 - acc: 0.9963 - val_loss: 0.0117 - val_acc: 0.9980\n",
            "Epoch 812/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0211 - acc: 0.9948 - val_loss: 0.0095 - val_acc: 0.9985\n",
            "Epoch 813/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0253 - acc: 0.9944 - val_loss: 0.0177 - val_acc: 0.9954\n",
            "Epoch 814/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0303 - acc: 0.9947 - val_loss: 0.1760 - val_acc: 0.9819\n",
            "Epoch 815/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0198 - acc: 0.9957 - val_loss: 0.0156 - val_acc: 0.9967\n",
            "Epoch 816/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0203 - acc: 0.9947 - val_loss: 0.0094 - val_acc: 0.9986\n",
            "Epoch 817/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0201 - acc: 0.9956 - val_loss: 0.0110 - val_acc: 0.9983\n",
            "Epoch 818/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0190 - acc: 0.9958 - val_loss: 0.0717 - val_acc: 0.9776\n",
            "Epoch 819/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0231 - acc: 0.9946 - val_loss: 0.0098 - val_acc: 0.9989\n",
            "Epoch 820/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0193 - acc: 0.9954 - val_loss: 0.0144 - val_acc: 0.9967\n",
            "Epoch 821/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0267 - acc: 0.9942 - val_loss: 0.0126 - val_acc: 0.9972\n",
            "Epoch 822/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0241 - acc: 0.9958 - val_loss: 0.0199 - val_acc: 0.9972\n",
            "Epoch 823/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0328 - acc: 0.9929 - val_loss: 0.0198 - val_acc: 0.9942\n",
            "Epoch 824/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0239 - acc: 0.9956 - val_loss: 0.0082 - val_acc: 0.9984\n",
            "Epoch 825/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0271 - acc: 0.9946 - val_loss: 0.0100 - val_acc: 0.9983\n",
            "Epoch 826/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0234 - acc: 0.9946 - val_loss: 0.0247 - val_acc: 0.9940\n",
            "Epoch 827/1000\n",
            "54924/54924 [==============================] - 2s 30us/step - loss: 0.0189 - acc: 0.9953 - val_loss: 0.0138 - val_acc: 0.9965\n",
            "Epoch 828/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0193 - acc: 0.9957 - val_loss: 0.0107 - val_acc: 0.9984\n",
            "Epoch 829/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0267 - acc: 0.9943 - val_loss: 0.0254 - val_acc: 0.9964\n",
            "Epoch 830/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0483 - acc: 0.9920 - val_loss: 0.0120 - val_acc: 0.9990\n",
            "Epoch 831/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0279 - acc: 0.9951 - val_loss: 0.0300 - val_acc: 0.9953\n",
            "Epoch 832/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0361 - acc: 0.9941 - val_loss: 0.0095 - val_acc: 0.9983\n",
            "Epoch 833/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0317 - acc: 0.9949 - val_loss: 0.0233 - val_acc: 0.9951\n",
            "Epoch 834/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0326 - acc: 0.9957 - val_loss: 0.0170 - val_acc: 0.9977\n",
            "Epoch 835/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0471 - acc: 0.9933 - val_loss: 0.0209 - val_acc: 0.9968\n",
            "Epoch 836/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0336 - acc: 0.9945 - val_loss: 0.1120 - val_acc: 0.9730\n",
            "Epoch 837/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0609 - acc: 0.9916 - val_loss: 0.0146 - val_acc: 0.9980\n",
            "Epoch 838/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0471 - acc: 0.9929 - val_loss: 0.0096 - val_acc: 0.9988\n",
            "Epoch 839/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0299 - acc: 0.9956 - val_loss: 0.0284 - val_acc: 0.9939\n",
            "Epoch 840/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0526 - acc: 0.9933 - val_loss: 0.0152 - val_acc: 0.9983\n",
            "Epoch 841/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0334 - acc: 0.9954 - val_loss: 0.0130 - val_acc: 0.9984\n",
            "Epoch 842/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0415 - acc: 0.9949 - val_loss: 0.0262 - val_acc: 0.9948\n",
            "Epoch 843/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0621 - acc: 0.9922 - val_loss: 0.0132 - val_acc: 0.9986\n",
            "Epoch 844/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0393 - acc: 0.9947 - val_loss: 0.0229 - val_acc: 0.9964\n",
            "Epoch 845/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0287 - acc: 0.9959 - val_loss: 0.0146 - val_acc: 0.9982\n",
            "Epoch 846/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0601 - acc: 0.9921 - val_loss: 0.0140 - val_acc: 0.9982\n",
            "Epoch 847/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0218 - acc: 0.9958 - val_loss: 0.0072 - val_acc: 0.9993\n",
            "Epoch 848/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0177 - acc: 0.9959 - val_loss: 0.0187 - val_acc: 0.9956\n",
            "Epoch 849/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0259 - acc: 0.9944 - val_loss: 0.0111 - val_acc: 0.9981\n",
            "Epoch 850/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0256 - acc: 0.9941 - val_loss: 0.0091 - val_acc: 0.9986\n",
            "Epoch 851/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0196 - acc: 0.9954 - val_loss: 0.0117 - val_acc: 0.9980\n",
            "Epoch 852/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0209 - acc: 0.9956 - val_loss: 0.0143 - val_acc: 0.9988\n",
            "Epoch 853/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0262 - acc: 0.9938 - val_loss: 0.0130 - val_acc: 0.9972\n",
            "Epoch 854/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0198 - acc: 0.9951 - val_loss: 0.1138 - val_acc: 0.9659\n",
            "Epoch 855/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0189 - acc: 0.9956 - val_loss: 0.0085 - val_acc: 0.9993\n",
            "Epoch 856/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0281 - acc: 0.9945 - val_loss: 0.0103 - val_acc: 0.9988\n",
            "Epoch 857/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0859 - acc: 0.9900 - val_loss: 0.0106 - val_acc: 0.9984\n",
            "Epoch 858/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0195 - acc: 0.9961 - val_loss: 0.0142 - val_acc: 0.9980\n",
            "Epoch 859/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0160 - acc: 0.9961 - val_loss: 0.0797 - val_acc: 0.9883\n",
            "Epoch 860/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0177 - acc: 0.9958 - val_loss: 0.0120 - val_acc: 0.9973\n",
            "Epoch 861/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0161 - acc: 0.9962 - val_loss: 0.0181 - val_acc: 0.9964\n",
            "Epoch 862/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0607 - acc: 0.9922 - val_loss: 0.0113 - val_acc: 0.9985\n",
            "Epoch 863/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0202 - acc: 0.9954 - val_loss: 0.0100 - val_acc: 0.9988\n",
            "Epoch 864/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0256 - acc: 0.9941 - val_loss: 0.0194 - val_acc: 0.9948\n",
            "Epoch 865/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0261 - acc: 0.9940 - val_loss: 0.0151 - val_acc: 0.9962\n",
            "Epoch 866/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0208 - acc: 0.9954 - val_loss: 0.0122 - val_acc: 0.9984\n",
            "Epoch 867/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0384 - acc: 0.9951 - val_loss: 0.0194 - val_acc: 0.9971\n",
            "Epoch 868/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0582 - acc: 0.9933 - val_loss: 0.0192 - val_acc: 0.9977\n",
            "Epoch 869/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0366 - acc: 0.9948 - val_loss: 0.0391 - val_acc: 0.9942\n",
            "Epoch 870/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0499 - acc: 0.9939 - val_loss: 0.0134 - val_acc: 0.9983\n",
            "Epoch 871/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0285 - acc: 0.9959 - val_loss: 0.1122 - val_acc: 0.9743\n",
            "Epoch 872/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0306 - acc: 0.9959 - val_loss: 0.3186 - val_acc: 0.9380\n",
            "Epoch 873/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0693 - acc: 0.9914 - val_loss: 0.0112 - val_acc: 0.9990\n",
            "Epoch 874/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0472 - acc: 0.9946 - val_loss: 0.0141 - val_acc: 0.9985\n",
            "Epoch 875/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0420 - acc: 0.9939 - val_loss: 0.0225 - val_acc: 0.9966\n",
            "Epoch 876/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0375 - acc: 0.9950 - val_loss: 0.0140 - val_acc: 0.9987\n",
            "Epoch 877/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0391 - acc: 0.9946 - val_loss: 0.0089 - val_acc: 0.9991\n",
            "Epoch 878/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0513 - acc: 0.9930 - val_loss: 0.1251 - val_acc: 0.9870\n",
            "Epoch 879/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0722 - acc: 0.9921 - val_loss: 0.0142 - val_acc: 0.9983\n",
            "Epoch 880/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0344 - acc: 0.9944 - val_loss: 0.1807 - val_acc: 0.9560\n",
            "Epoch 881/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0399 - acc: 0.9942 - val_loss: 0.1100 - val_acc: 0.9882\n",
            "Epoch 882/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0264 - acc: 0.9963 - val_loss: 0.0123 - val_acc: 0.9984\n",
            "Epoch 883/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0404 - acc: 0.9940 - val_loss: 0.0469 - val_acc: 0.9931\n",
            "Epoch 884/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0497 - acc: 0.9933 - val_loss: 0.0177 - val_acc: 0.9977\n",
            "Epoch 885/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0510 - acc: 0.9935 - val_loss: 0.0810 - val_acc: 0.9904\n",
            "Epoch 886/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0504 - acc: 0.9925 - val_loss: 0.0424 - val_acc: 0.9918\n",
            "Epoch 887/1000\n",
            "54924/54924 [==============================] - 2s 30us/step - loss: 0.0379 - acc: 0.9945 - val_loss: 0.0085 - val_acc: 0.9991\n",
            "Epoch 888/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0343 - acc: 0.9953 - val_loss: 0.0685 - val_acc: 0.9915\n",
            "Epoch 889/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0283 - acc: 0.9957 - val_loss: 0.0072 - val_acc: 0.9995\n",
            "Epoch 890/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0423 - acc: 0.9939 - val_loss: 0.0276 - val_acc: 0.9948\n",
            "Epoch 891/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0309 - acc: 0.9958 - val_loss: 0.0114 - val_acc: 0.9988\n",
            "Epoch 892/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0655 - acc: 0.9908 - val_loss: 0.0283 - val_acc: 0.9949\n",
            "Epoch 893/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0219 - acc: 0.9967 - val_loss: 0.0374 - val_acc: 0.9937\n",
            "Epoch 894/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0522 - acc: 0.9918 - val_loss: 0.0132 - val_acc: 0.9984\n",
            "Epoch 895/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0145 - acc: 0.9968 - val_loss: 0.0082 - val_acc: 0.9988\n",
            "Epoch 896/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0185 - acc: 0.9960 - val_loss: 0.2169 - val_acc: 0.9266\n",
            "Epoch 897/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0231 - acc: 0.9947 - val_loss: 0.0106 - val_acc: 0.9983\n",
            "Epoch 898/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0187 - acc: 0.9964 - val_loss: 0.0082 - val_acc: 0.9984\n",
            "Epoch 899/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0176 - acc: 0.9959 - val_loss: 0.0074 - val_acc: 0.9992\n",
            "Epoch 900/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0167 - acc: 0.9966 - val_loss: 0.0098 - val_acc: 0.9981\n",
            "Epoch 901/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0247 - acc: 0.9944 - val_loss: 0.0530 - val_acc: 0.9859\n",
            "Epoch 902/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0229 - acc: 0.9951 - val_loss: 0.0242 - val_acc: 0.9932\n",
            "Epoch 903/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0236 - acc: 0.9946 - val_loss: 0.0608 - val_acc: 0.9891\n",
            "Epoch 904/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0211 - acc: 0.9956 - val_loss: 0.0102 - val_acc: 0.9987\n",
            "Epoch 905/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0215 - acc: 0.9950 - val_loss: 0.0223 - val_acc: 0.9944\n",
            "Epoch 906/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0228 - acc: 0.9950 - val_loss: 0.0106 - val_acc: 0.9988\n",
            "Epoch 907/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0186 - acc: 0.9959 - val_loss: 0.0160 - val_acc: 0.9957\n",
            "Epoch 908/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0218 - acc: 0.9952 - val_loss: 0.0099 - val_acc: 0.9982\n",
            "Epoch 909/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0210 - acc: 0.9951 - val_loss: 0.0112 - val_acc: 0.9979\n",
            "Epoch 910/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0254 - acc: 0.9945 - val_loss: 0.0154 - val_acc: 0.9956\n",
            "Epoch 911/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0176 - acc: 0.9966 - val_loss: 0.0135 - val_acc: 0.9969\n",
            "Epoch 912/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0257 - acc: 0.9948 - val_loss: 0.0154 - val_acc: 0.9964\n",
            "Epoch 913/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0370 - acc: 0.9942 - val_loss: 0.0136 - val_acc: 0.9977\n",
            "Epoch 914/1000\n",
            "54924/54924 [==============================] - 1s 26us/step - loss: 0.0570 - acc: 0.9928 - val_loss: 0.0134 - val_acc: 0.9983\n",
            "Epoch 915/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0483 - acc: 0.9938 - val_loss: 0.0776 - val_acc: 0.9908\n",
            "Epoch 916/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0485 - acc: 0.9936 - val_loss: 0.0448 - val_acc: 0.9936\n",
            "Epoch 917/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0612 - acc: 0.9930 - val_loss: 0.0570 - val_acc: 0.9932\n",
            "Epoch 918/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.1098 - acc: 0.9898 - val_loss: 0.0182 - val_acc: 0.9985\n",
            "Epoch 919/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0507 - acc: 0.9936 - val_loss: 0.0696 - val_acc: 0.9926\n",
            "Epoch 920/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0428 - acc: 0.9947 - val_loss: 0.0086 - val_acc: 0.9993\n",
            "Epoch 921/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0856 - acc: 0.9894 - val_loss: 0.0344 - val_acc: 0.9948\n",
            "Epoch 922/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0260 - acc: 0.9966 - val_loss: 0.0109 - val_acc: 0.9988\n",
            "Epoch 923/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0297 - acc: 0.9958 - val_loss: 0.0085 - val_acc: 0.9989\n",
            "Epoch 924/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0637 - acc: 0.9916 - val_loss: 0.0160 - val_acc: 0.9980\n",
            "Epoch 925/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0476 - acc: 0.9938 - val_loss: 0.1124 - val_acc: 0.9884\n",
            "Epoch 926/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0380 - acc: 0.9949 - val_loss: 0.0220 - val_acc: 0.9972\n",
            "Epoch 927/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0480 - acc: 0.9932 - val_loss: 0.1307 - val_acc: 0.9792\n",
            "Epoch 928/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0385 - acc: 0.9955 - val_loss: 0.0179 - val_acc: 0.9971\n",
            "Epoch 929/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0425 - acc: 0.9935 - val_loss: 0.0293 - val_acc: 0.9957\n",
            "Epoch 930/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0236 - acc: 0.9969 - val_loss: 0.0182 - val_acc: 0.9977\n",
            "Epoch 931/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0375 - acc: 0.9946 - val_loss: 0.0772 - val_acc: 0.9910\n",
            "Epoch 932/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0911 - acc: 0.9898 - val_loss: 0.0110 - val_acc: 0.9989\n",
            "Epoch 933/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0293 - acc: 0.9956 - val_loss: 0.0097 - val_acc: 0.9990\n",
            "Epoch 934/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0383 - acc: 0.9951 - val_loss: 0.0641 - val_acc: 0.9923\n",
            "Epoch 935/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0631 - acc: 0.9912 - val_loss: 0.0526 - val_acc: 0.9931\n",
            "Epoch 936/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0463 - acc: 0.9942 - val_loss: 0.0152 - val_acc: 0.9988\n",
            "Epoch 937/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0445 - acc: 0.9946 - val_loss: 0.0073 - val_acc: 0.9996\n",
            "Epoch 938/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0484 - acc: 0.9946 - val_loss: 0.1800 - val_acc: 0.9479\n",
            "Epoch 939/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0346 - acc: 0.9951 - val_loss: 0.0184 - val_acc: 0.9990\n",
            "Epoch 940/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0252 - acc: 0.9961 - val_loss: 1.2007 - val_acc: 0.8568\n",
            "Epoch 941/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0711 - acc: 0.9909 - val_loss: 0.0066 - val_acc: 0.9994\n",
            "Epoch 942/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0485 - acc: 0.9944 - val_loss: 0.0216 - val_acc: 0.9981\n",
            "Epoch 943/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0570 - acc: 0.9931 - val_loss: 0.0227 - val_acc: 0.9960\n",
            "Epoch 944/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0282 - acc: 0.9960 - val_loss: 0.0183 - val_acc: 0.9966\n",
            "Epoch 945/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0277 - acc: 0.9961 - val_loss: 0.0091 - val_acc: 0.9987\n",
            "Epoch 946/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0435 - acc: 0.9946 - val_loss: 0.0162 - val_acc: 0.9980\n",
            "Epoch 947/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0621 - acc: 0.9932 - val_loss: 0.0178 - val_acc: 0.9973\n",
            "Epoch 948/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.1161 - acc: 0.9895 - val_loss: 0.0652 - val_acc: 0.9808\n",
            "Epoch 949/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0433 - acc: 0.9940 - val_loss: 0.0964 - val_acc: 0.9824\n",
            "Epoch 950/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0497 - acc: 0.9934 - val_loss: 0.0147 - val_acc: 0.9982\n",
            "Epoch 951/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0464 - acc: 0.9936 - val_loss: 0.0117 - val_acc: 0.9990\n",
            "Epoch 952/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0311 - acc: 0.9962 - val_loss: 0.0819 - val_acc: 0.9904\n",
            "Epoch 953/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0685 - acc: 0.9908 - val_loss: 0.0121 - val_acc: 0.9988\n",
            "Epoch 954/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0290 - acc: 0.9960 - val_loss: 0.0281 - val_acc: 0.9945\n",
            "Epoch 955/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0244 - acc: 0.9967 - val_loss: 0.0116 - val_acc: 0.9985\n",
            "Epoch 956/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0592 - acc: 0.9922 - val_loss: 0.0134 - val_acc: 0.9983\n",
            "Epoch 957/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0331 - acc: 0.9952 - val_loss: 0.0138 - val_acc: 0.9988\n",
            "Epoch 958/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0204 - acc: 0.9964 - val_loss: 0.0128 - val_acc: 0.9967\n",
            "Epoch 959/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0189 - acc: 0.9962 - val_loss: 0.0193 - val_acc: 0.9956\n",
            "Epoch 960/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0247 - acc: 0.9950 - val_loss: 0.0755 - val_acc: 0.9731\n",
            "Epoch 961/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0234 - acc: 0.9950 - val_loss: 0.0123 - val_acc: 0.9968\n",
            "Epoch 962/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0213 - acc: 0.9951 - val_loss: 0.0209 - val_acc: 0.9942\n",
            "Epoch 963/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0207 - acc: 0.9952 - val_loss: 0.0408 - val_acc: 0.9920\n",
            "Epoch 964/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0365 - acc: 0.9919 - val_loss: 0.0334 - val_acc: 0.9959\n",
            "Epoch 965/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0226 - acc: 0.9946 - val_loss: 0.0120 - val_acc: 0.9984\n",
            "Epoch 966/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0162 - acc: 0.9962 - val_loss: 0.0200 - val_acc: 0.9945\n",
            "Epoch 967/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0186 - acc: 0.9963 - val_loss: 0.0111 - val_acc: 0.9980\n",
            "Epoch 968/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0195 - acc: 0.9962 - val_loss: 0.0083 - val_acc: 0.9985\n",
            "Epoch 969/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0223 - acc: 0.9946 - val_loss: 0.0585 - val_acc: 0.9775\n",
            "Epoch 970/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0239 - acc: 0.9945 - val_loss: 0.0193 - val_acc: 0.9948\n",
            "Epoch 971/1000\n",
            "54924/54924 [==============================] - 1s 27us/step - loss: 0.0197 - acc: 0.9959 - val_loss: 0.0135 - val_acc: 0.9977\n",
            "Epoch 972/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0196 - acc: 0.9958 - val_loss: 0.0363 - val_acc: 0.9915\n",
            "Epoch 973/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0282 - acc: 0.9942 - val_loss: 0.0126 - val_acc: 0.9985\n",
            "Epoch 974/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0250 - acc: 0.9950 - val_loss: 0.0360 - val_acc: 0.9939\n",
            "Epoch 975/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0234 - acc: 0.9959 - val_loss: 0.0092 - val_acc: 0.9991\n",
            "Epoch 976/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0274 - acc: 0.9954 - val_loss: 0.1788 - val_acc: 0.9545\n",
            "Epoch 977/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0401 - acc: 0.9933 - val_loss: 0.0088 - val_acc: 0.9988\n",
            "Epoch 978/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0449 - acc: 0.9939 - val_loss: 0.0136 - val_acc: 0.9981\n",
            "Epoch 979/1000\n",
            "54924/54924 [==============================] - 2s 30us/step - loss: 0.0276 - acc: 0.9960 - val_loss: 0.0192 - val_acc: 0.9964\n",
            "Epoch 980/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0196 - acc: 0.9971 - val_loss: 0.0130 - val_acc: 0.9975\n",
            "Epoch 981/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0211 - acc: 0.9960 - val_loss: 0.0280 - val_acc: 0.9904\n",
            "Epoch 982/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0240 - acc: 0.9959 - val_loss: 0.0139 - val_acc: 0.9973\n",
            "Epoch 983/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0220 - acc: 0.9957 - val_loss: 0.0104 - val_acc: 0.9991\n",
            "Epoch 984/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0236 - acc: 0.9965 - val_loss: 0.0167 - val_acc: 0.9964\n",
            "Epoch 985/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0218 - acc: 0.9953 - val_loss: 0.0106 - val_acc: 0.9985\n",
            "Epoch 986/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0278 - acc: 0.9941 - val_loss: 0.0192 - val_acc: 0.9948\n",
            "Epoch 987/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0176 - acc: 0.9960 - val_loss: 0.0532 - val_acc: 0.9912\n",
            "Epoch 988/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0234 - acc: 0.9949 - val_loss: 0.0337 - val_acc: 0.9929\n",
            "Epoch 989/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0249 - acc: 0.9944 - val_loss: 0.0141 - val_acc: 0.9964\n",
            "Epoch 990/1000\n",
            "54924/54924 [==============================] - 2s 29us/step - loss: 0.0272 - acc: 0.9940 - val_loss: 0.0443 - val_acc: 0.9894\n",
            "Epoch 991/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0184 - acc: 0.9959 - val_loss: 0.0085 - val_acc: 0.9989\n",
            "Epoch 992/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0165 - acc: 0.9967 - val_loss: 0.0143 - val_acc: 0.9972\n",
            "Epoch 993/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0201 - acc: 0.9962 - val_loss: 0.3244 - val_acc: 0.9255\n",
            "Epoch 994/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0259 - acc: 0.9952 - val_loss: 0.0169 - val_acc: 0.9963\n",
            "Epoch 995/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0228 - acc: 0.9946 - val_loss: 0.0125 - val_acc: 0.9977\n",
            "Epoch 996/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0162 - acc: 0.9962 - val_loss: 0.0058 - val_acc: 0.9989\n",
            "Epoch 997/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0178 - acc: 0.9958 - val_loss: 0.0481 - val_acc: 0.9917\n",
            "Epoch 998/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0247 - acc: 0.9949 - val_loss: 0.0487 - val_acc: 0.9853\n",
            "Epoch 999/1000\n",
            "54924/54924 [==============================] - 2s 27us/step - loss: 0.0257 - acc: 0.9940 - val_loss: 0.0158 - val_acc: 0.9965\n",
            "Epoch 1000/1000\n",
            "54924/54924 [==============================] - 2s 28us/step - loss: 0.0226 - acc: 0.9947 - val_loss: 0.0115 - val_acc: 0.9975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x6RFAgEdZvNJ",
        "colab_type": "code",
        "outputId": "01ac6c07-cdcb-45dc-8794-4d13d1e2a964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        }
      },
      "cell_type": "code",
      "source": [
        "Y_predict = model.predict(X_test)\n",
        "Y_predict =(Y_predict>0.5)\n",
        "print(confusion_matrix(Y_test, Y_predict))\n",
        "print(classification_report(Y_test, Y_predict))\n",
        "\n",
        "#I Guess this shows that the model is decently fit as both the training and the test data both have good accuracy?\n",
        "pyplot.plot(history.history['acc'])\n",
        "pyplot.plot(history.history['val_acc'])\n",
        "pyplot.title('Model Train vs Test Accuracy')\n",
        "pyplot.ylabel('accuracy')\n",
        "pyplot.xlabel('epoch')\n",
        "pyplot.legend(['train', 'test'], loc='upper left')\n",
        "pyplot.show()\n",
        "\n",
        "pyplot.plot(history.history['loss'])\n",
        "pyplot.plot(history.history['val_loss'])\n",
        "pyplot.title('Model Train vs Test loss')\n",
        "pyplot.ylabel('loss')\n",
        "pyplot.xlabel('epoch')\n",
        "pyplot.legend(['train', 'test'], loc='upper left')\n",
        "pyplot.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[27892    67]\n",
            " [   15  1450]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00     27959\n",
            "        True       0.96      0.99      0.97      1465\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     29424\n",
            "   macro avg       0.98      0.99      0.99     29424\n",
            "weighted avg       1.00      1.00      1.00     29424\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAFnCAYAAAChL+DqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERExOYW9iIiIySnsRURETO7/A4wSfpHyKxV9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neYuIiHgZNW8REREvo+YtIiLiZf4XLD/9DdBm36wAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}